{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d39a1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Components\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Python Standard Library\n",
    "import ast  # For parsing NER strings\n",
    "import re   # For text parsing\n",
    "from typing import List, Dict, Any\n",
    "import hashlib  # For generating stable IDs\n",
    "\n",
    "# Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588f74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Testing data loaders...\n",
      "\n",
      "âœ… cleaned_recipes.csv: 1090 documents\n",
      "âœ… cleaned_recipes_data_sample.csv: 2000 documents\n",
      "âœ… cleaned_healthy_meals.csv: 2000 documents\n",
      "âœ… cleaned_nutrition.csv: 8789 documents\n",
      "\n",
      "ğŸ“Š Total: 13879 documents\n",
      "\n",
      "ğŸ” Sample Recipe Document:\n",
      "Text (first 300 chars):\n",
      "Recipe: Apple-Cranberry Crostada\n",
      "Cuisine: /Desserts/Fruit Desserts/Apple Dessert Recipes/\n",
      "Ingredients:\n",
      "3 tablespoons butter, 2 pounds Granny Smith apples (or other firm, crisp apples), peeled, quartered, cored and sliced 1/4-inch thick, 1 pound Macintosh apples (or other soft-textured apples that fa...\n",
      "\n",
      "Metadata:\n",
      "{'doc_type': 'recipe', 'source_file': 'cleaned_recipes', 'recipe_name': 'Apple-Cranberry Crostada', 'servings': 8, 'cuisine': '', 'allergens': ['dairy', 'eggs'], 'diet_tags': ['vegetarian']}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Data Loading Functions\n",
    "# ========================================\n",
    "\n",
    "def load_recipes_csv(csv_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load cleaned_recipes.csv with structured nutrition parsing\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Skip duplicates\n",
    "        if pd.isna(row['recipe_name']):\n",
    "            continue\n",
    "            \n",
    "        # Build narrative text for embedding\n",
    "        text_parts = [\n",
    "            f\"Recipe: {row['recipe_name']}\",\n",
    "            f\"\\nCuisine: {row.get('cuisine_path', 'Not specified')}\",\n",
    "            f\"\\nIngredients:\\n{row['ingredients']}\",\n",
    "            f\"\\nDirections:\\n{row['directions']}\"\n",
    "        ]\n",
    "        \n",
    "        # Add timing if available\n",
    "        if pd.notna(row.get('prep_time')):\n",
    "            text_parts.append(f\"\\nPrep Time: {row['prep_time']}\")\n",
    "        if pd.notna(row.get('cook_time')):\n",
    "            text_parts.append(f\"\\nCook Time: {row['cook_time']}\")\n",
    "        \n",
    "        # Add nutrition info\n",
    "        if pd.notna(row.get('nutrition')):\n",
    "            text_parts.append(f\"\\nNutrition Facts: {row['nutrition']}\")\n",
    "        \n",
    "        full_text = \"\".join(text_parts)\n",
    "        \n",
    "        # Extract metadata\n",
    "        metadata = {\n",
    "            'doc_type': 'recipe',\n",
    "            'source_file': 'cleaned_recipes',\n",
    "            'recipe_name': row['recipe_name'],\n",
    "            'servings': row.get('servings', 'Not specified'),\n",
    "        }\n",
    "        \n",
    "        # Parse cuisine\n",
    "        if pd.notna(row.get('cuisine_path')):\n",
    "            cuisine = row['cuisine_path'].split('/')[-1] if '/' in str(row['cuisine_path']) else row['cuisine_path']\n",
    "            metadata['cuisine'] = cuisine\n",
    "        \n",
    "        # Parse timing (convert to minutes)\n",
    "        if pd.notna(row.get('prep_time')):\n",
    "            prep_str = str(row['prep_time']).lower()\n",
    "            prep_mins = sum([int(s) * (60 if 'hr' in prep_str else 1) \n",
    "                           for s in re.findall(r'\\d+', prep_str)])\n",
    "            metadata['prep_time_min'] = prep_mins\n",
    "        \n",
    "        if pd.notna(row.get('cook_time')):\n",
    "            cook_str = str(row['cook_time']).lower()\n",
    "            cook_mins = sum([int(s) * (60 if 'hr' in cook_str else 1) \n",
    "                           for s in re.findall(r'\\d+', cook_str)])\n",
    "            metadata['cook_time_min'] = cook_mins\n",
    "        \n",
    "        # Extract allergens from ingredients (basic heuristic)\n",
    "        ingredients_lower = str(row['ingredients']).lower()\n",
    "        allergens = []\n",
    "        if any(word in ingredients_lower for word in ['milk', 'cheese', 'butter', 'cream', 'yogurt']):\n",
    "            allergens.append('dairy')\n",
    "        if any(word in ingredients_lower for word in ['egg']):\n",
    "            allergens.append('eggs')\n",
    "        if any(word in ingredients_lower for word in ['wheat', 'flour', 'bread']):\n",
    "            allergens.append('gluten')\n",
    "        if any(word in ingredients_lower for word in ['nuts', 'almond', 'peanut', 'walnut']):\n",
    "            allergens.append('nuts')\n",
    "        metadata['allergens'] = allergens\n",
    "        \n",
    "        # Dietary tags (heuristic)\n",
    "        diet_tags = []\n",
    "        if 'vegetarian' in ingredients_lower or 'veggie' in ingredients_lower:\n",
    "            diet_tags.append('vegetarian')\n",
    "        if 'vegan' in ingredients_lower:\n",
    "            diet_tags.append('vegan')\n",
    "        if not any(meat in ingredients_lower for meat in ['chicken', 'beef', 'pork', 'fish', 'meat']):\n",
    "            diet_tags.append('vegetarian')\n",
    "        metadata['diet_tags'] = diet_tags\n",
    "        \n",
    "        documents.append(Document(page_content=full_text, metadata=metadata))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_recipes_data_sample_csv(csv_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load cleaned_recipes_data_sample.csv with NER parsing\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['title']):\n",
    "            continue\n",
    "        \n",
    "        # Parse ingredients list\n",
    "        try:\n",
    "            ingredients_list = ast.literal_eval(row['ingredients'])\n",
    "            ingredients_text = \"\\n\".join([f\"- {ing}\" for ing in ingredients_list])\n",
    "        except:\n",
    "            ingredients_text = row['ingredients']\n",
    "        \n",
    "        # Parse directions list\n",
    "        try:\n",
    "            directions_list = ast.literal_eval(row['directions'])\n",
    "            directions_text = \"\\n\".join([f\"{i+1}. {step}\" for i, step in enumerate(directions_list)])\n",
    "        except:\n",
    "            directions_text = row['directions']\n",
    "        \n",
    "        # Parse NER (Named Entity Recognition - extracted ingredients)\n",
    "        try:\n",
    "            ner_list = ast.literal_eval(row['NER'])\n",
    "            ner_text = \", \".join(ner_list)\n",
    "        except:\n",
    "            ner_list = []\n",
    "            ner_text = \"\"\n",
    "        \n",
    "        # Build text\n",
    "        text_parts = [\n",
    "            f\"Recipe: {row['title']}\",\n",
    "            f\"\\nIngredients:\\n{ingredients_text}\",\n",
    "            f\"\\nDirections:\\n{directions_text}\",\n",
    "            f\"\\nKey Ingredients: {ner_text}\"\n",
    "        ]\n",
    "        \n",
    "        full_text = \"\".join(text_parts)\n",
    "        \n",
    "        # Extract metadata\n",
    "        metadata = {\n",
    "            'doc_type': 'recipe',\n",
    "            'source_file': 'cleaned_recipes_data_sample',\n",
    "            'recipe_name': row['title'],\n",
    "            'ingredient_list': ner_list if ner_list else None\n",
    "        }\n",
    "        \n",
    "        # Extract allergens\n",
    "        ingredients_lower = str(row['ingredients']).lower()\n",
    "        allergens = []\n",
    "        if any(word in ingredients_lower for word in ['milk', 'cheese', 'butter', 'cream', 'yogurt']):\n",
    "            allergens.append('dairy')\n",
    "        if any(word in ingredients_lower for word in ['egg']):\n",
    "            allergens.append('eggs')\n",
    "        if any(word in ingredients_lower for word in ['wheat', 'flour', 'bread']):\n",
    "            allergens.append('gluten')\n",
    "        if any(word in ingredients_lower for word in ['nuts', 'almond', 'peanut', 'walnut']):\n",
    "            allergens.append('nuts')\n",
    "        metadata['allergens'] = allergens\n",
    "        \n",
    "        # Dietary tags\n",
    "        diet_tags = []\n",
    "        if not any(meat in ingredients_lower for meat in ['chicken', 'beef', 'pork', 'fish', 'meat', 'lamb']):\n",
    "            diet_tags.append('vegetarian')\n",
    "        metadata['diet_tags'] = diet_tags\n",
    "        \n",
    "        documents.append(Document(page_content=full_text, metadata=metadata))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_healthy_meals_csv(csv_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load cleaned_healthy_meals.csv with numeric nutrition metadata\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['meal_name']):\n",
    "            continue\n",
    "        \n",
    "        # Build concise text\n",
    "        text = f\"\"\"Meal: {row['meal_name']} ({row['cuisine']} {row['meal_type']})\n",
    "Diet Type: {row['diet_type']}\n",
    "\n",
    "Nutrition per {row['serving_size_g']}g serving:\n",
    "- Calories: {row['calories']} kcal\n",
    "- Protein: {row['protein_g']}g | Carbs: {row['carbs_g']}g | Fat: {row['fat_g']}g\n",
    "- Fiber: {row['fiber_g']}g | Sugar: {row['sugar_g']}g\n",
    "- Sodium: {row['sodium_mg']}mg | Cholesterol: {row['cholesterol_mg']}mg\n",
    "\n",
    "Preparation: {row['cooking_method']} (Prep: {row['prep_time_min']}min, Cook: {row['cook_time_min']}min)\n",
    "\"\"\"\n",
    "        \n",
    "        # Metadata with numeric values for filtering\n",
    "        metadata = {\n",
    "            'doc_type': 'meal',\n",
    "            'source_file': 'cleaned_healthy_meals',\n",
    "            'recipe_name': row['meal_name'],\n",
    "            'cuisine': row['cuisine'],\n",
    "            'meal_type': row['meal_type'],\n",
    "            'diet_type': row['diet_type'],\n",
    "            'calories': int(row['calories']),\n",
    "            'protein_g': float(row['protein_g']),\n",
    "            'carbs_g': float(row['carbs_g']),\n",
    "            'fat_g': float(row['fat_g']),\n",
    "            'fiber_g': float(row['fiber_g']),\n",
    "            'sugar_g': float(row['sugar_g']),\n",
    "            'sodium_mg': int(row['sodium_mg']),\n",
    "            'cholesterol_mg': int(row['cholesterol_mg']),\n",
    "            'serving_size_g': int(row['serving_size_g']),\n",
    "            'cooking_method': row['cooking_method'],\n",
    "            'prep_time_min': int(row['prep_time_min']),\n",
    "            'cook_time_min': int(row['cook_time_min'])\n",
    "        }\n",
    "        \n",
    "        # Diet tags from diet_type\n",
    "        diet_tags = [row['diet_type'].lower()]\n",
    "        if row['diet_type'].lower() in ['vegan', 'vegetarian']:\n",
    "            diet_tags.append('vegetarian')\n",
    "        metadata['diet_tags'] = diet_tags\n",
    "        \n",
    "        # Allergen inference (basic)\n",
    "        allergens = []\n",
    "        meal_lower = row['meal_name'].lower()\n",
    "        if any(word in meal_lower for word in ['cheese', 'yogurt', 'milk']):\n",
    "            allergens.append('dairy')\n",
    "        metadata['allergens'] = allergens\n",
    "        \n",
    "        documents.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_nutrition_csv(csv_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load cleaned_nutrition.csv - detailed ingredient nutrition database\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.isna(row['name']):\n",
    "            continue\n",
    "        \n",
    "        # Build detailed nutrition text\n",
    "        text = f\"\"\"Ingredient: {row['name']} (per {row['serving_size']})\n",
    "\n",
    "Macronutrients:\n",
    "- Calories: {row['calories']} kcal\n",
    "- Protein: {row['protein']}\n",
    "- Carbohydrates: {row['carbohydrate']}\n",
    "- Total Fat: {row['total_fat']}\n",
    "- Fiber: {row['fiber']}\n",
    "- Sugars: {row['sugars']}\n",
    "\n",
    "Key Vitamins:\n",
    "- Vitamin A: {row['vitamin_a']}\n",
    "- Vitamin C: {row['vitamin_c']}\n",
    "- Vitamin D: {row['vitamin_d']}\n",
    "- Vitamin B12: {row['vitamin_b12']}\n",
    "- Folate: {row['folate']}\n",
    "\n",
    "Key Minerals:\n",
    "- Calcium: {row['calcium']}\n",
    "- Iron: {row['irom']}\n",
    "- Magnesium: {row['magnesium']}\n",
    "- Sodium: {row['sodium']}\n",
    "- Potassium: {row['potassium']}\n",
    "\n",
    "Cholesterol: {row['cholesterol']} | Saturated Fat: {row['saturated_fat']}\n",
    "\"\"\"\n",
    "        \n",
    "        # Metadata\n",
    "        metadata = {\n",
    "            'doc_type': 'nutrition_fact',\n",
    "            'source_file': 'cleaned_nutrition',\n",
    "            'food_name': row['name'],\n",
    "            'serving_size': row['serving_size']\n",
    "        }\n",
    "        \n",
    "        # Extract numeric values (handle 'g', 'mg', 'mcg' suffixes)\n",
    "        def parse_numeric(val):\n",
    "            if pd.isna(val):\n",
    "                return None\n",
    "            try:\n",
    "                return float(re.sub(r'[^\\d.]', '', str(val)))\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        metadata['calories'] = parse_numeric(row['calories'])\n",
    "        metadata['protein_g'] = parse_numeric(row['protein'])\n",
    "        metadata['carbs_g'] = parse_numeric(row['carbohydrate'])\n",
    "        metadata['fat_g'] = parse_numeric(row['total_fat'])\n",
    "        metadata['fiber_g'] = parse_numeric(row['fiber'])\n",
    "        metadata['sugar_g'] = parse_numeric(row['sugars'])\n",
    "        \n",
    "        # Allergen detection\n",
    "        food_lower = row['name'].lower()\n",
    "        allergens = []\n",
    "        if any(word in food_lower for word in ['milk', 'cheese', 'yogurt', 'cream', 'butter']):\n",
    "            allergens.append('dairy')\n",
    "        if any(word in food_lower for word in ['egg']):\n",
    "            allergens.append('eggs')\n",
    "        if any(word in food_lower for word in ['wheat', 'flour', 'bread']):\n",
    "            allergens.append('gluten')\n",
    "        if any(word in food_lower for word in ['nuts', 'almond', 'peanut', 'walnut', 'pecan']):\n",
    "            allergens.append('nuts')\n",
    "        metadata['allergens'] = allergens\n",
    "        \n",
    "        documents.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_loaders():\n",
    "    \"\"\"Quick test to verify loaders work\"\"\"\n",
    "    print(\"ğŸ”„ Testing data loaders...\\n\")\n",
    "    \n",
    "    # Test each loader\n",
    "    recipes1 = load_recipes_csv('../data/cleaned_recipes.csv')\n",
    "    print(f\"âœ… cleaned_recipes.csv: {len(recipes1)} documents\")\n",
    "    \n",
    "    recipes2 = load_recipes_data_sample_csv('../data/cleaned_recipes_data_sample.csv')\n",
    "    print(f\"âœ… cleaned_recipes_data_sample.csv: {len(recipes2)} documents\")\n",
    "    \n",
    "    meals = load_healthy_meals_csv('../data/cleaned_healthy_meals.csv')\n",
    "    print(f\"âœ… cleaned_healthy_meals.csv: {len(meals)} documents\")\n",
    "    \n",
    "    nutrition = load_nutrition_csv('../data/cleaned_nutrition.csv')\n",
    "    print(f\"âœ… cleaned_nutrition.csv: {len(nutrition)} documents\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total: {len(recipes1) + len(recipes2) + len(meals) + len(nutrition)} documents\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nğŸ” Sample Recipe Document:\")\n",
    "    print(f\"Text (first 300 chars):\\n{recipes1[0].page_content[:300]}...\")\n",
    "    print(f\"\\nMetadata:\\n{recipes1[0].metadata}\")\n",
    "\n",
    "# Run test\n",
    "test_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3d9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading CSV files...\n",
      "ğŸ“Š Collection 1 (RECIPES_AND_MEALS): 5090 documents\n",
      "ğŸ“Š Collection 2 (NUTRITION_FACTS): 8789 documents\n",
      "\n",
      "ğŸ§  Loading embedding model (sentence-transformers/all-mpnet-base-v2)...\n",
      "\n",
      "ğŸ”§ Creating FAISS vectorstore for RECIPES_AND_MEALS...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorstore_recipes, vectorstore_nutrition\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Build the collections\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m vectorstore_recipes, vectorstore_nutrition = \u001b[43mbuild_collections\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mbuild_collections\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Create FAISS vectorstores\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ”§ Creating FAISS vectorstore for RECIPES_AND_MEALS...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m vectorstore_recipes = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecipes_and_meals_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDistanceStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOSINE\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ”§ Creating FAISS vectorstore for NUTRITION_FACTS...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m vectorstore_nutrition = FAISS.from_documents(\n\u001b[32m     43\u001b[39m     documents=nutrition_facts_docs,\n\u001b[32m     44\u001b[39m     embedding=embeddings,\n\u001b[32m     45\u001b[39m     distance_strategy=DistanceStrategy.COSINE\n\u001b[32m     46\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:852\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    850\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:85\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     83\u001b[39m     sentence_transformers.SentenceTransformer.stop_multi_process_pool(pool)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     93\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected embeddings to be a Tensor or a numpy array, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgot a list instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:623\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m features.update(extra_features)\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    625\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:690\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    688\u001b[39m     module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m    689\u001b[39m     module_kwargs = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:393\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[32m    391\u001b[39m     trans_features[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m] = features[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m output_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m output_tokens = output_states[\u001b[32m0\u001b[39m]\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:486\u001b[39m, in \u001b[36mMPNetModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    484\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    485\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(input_ids=input_ids, position_ids=position_ids, inputs_embeds=inputs_embeds)\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    495\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:338\u001b[39m, in \u001b[36mMPNetEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    336\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:297\u001b[39m, in \u001b[36mMPNetLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    289\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    290\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     **kwargs,\n\u001b[32m    296\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    305\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:238\u001b[39m, in \u001b[36mMPNetAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    230\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    231\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     **kwargs,\n\u001b[32m    237\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.LayerNorm(\u001b[38;5;28mself\u001b[39m.dropout(self_outputs[\u001b[32m0\u001b[39m]) + hidden_states)\n\u001b[32m    246\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:198\u001b[39m, in \u001b[36mMPNetSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m new_c_shape = c.size()[:-\u001b[32m2\u001b[39m] + (\u001b[38;5;28mself\u001b[39m.all_head_size,)\n\u001b[32m    196\u001b[39m c = c.view(*new_c_shape)\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m o = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m outputs = (o, attention_probs) \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m (o,)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Build Collections with Embeddings\n",
    "# ========================================\n",
    "\n",
    "def build_collections():\n",
    "    \"\"\"\n",
    "    Build 2 separate FAISS collections:\n",
    "    1. RECIPES_AND_MEALS: Combined recipes + meals (for recipe search)\n",
    "    2. NUTRITION_FACTS: Ingredient nutrition database (for ingredient lookup)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Loading CSV files...\")\n",
    "    \n",
    "    # Load all documents\n",
    "    recipes1 = load_recipes_csv('../data/cleaned_recipes.csv')\n",
    "    recipes2 = load_recipes_data_sample_csv('../data/cleaned_recipes_data_sample.csv')\n",
    "    meals = load_healthy_meals_csv('../data/cleaned_healthy_meals.csv')\n",
    "    nutrition = load_nutrition_csv('../data/cleaned_nutrition.csv')\n",
    "    \n",
    "    # Combine into 2 collections\n",
    "    recipes_and_meals_docs = recipes1 + recipes2 + meals\n",
    "    nutrition_facts_docs = nutrition\n",
    "    \n",
    "    print(f\"ğŸ“Š Collection 1 (RECIPES_AND_MEALS): {len(recipes_and_meals_docs)} documents\")\n",
    "    print(f\"ğŸ“Š Collection 2 (NUTRITION_FACTS): {len(nutrition_facts_docs)} documents\")\n",
    "    \n",
    "    # Initialize embedding model\n",
    "    print(\"\\nğŸ§  Loading embedding model (sentence-transformers/all-mpnet-base-v2)...\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    \n",
    "    # Create FAISS vectorstores\n",
    "    print(\"\\nğŸ”§ Creating FAISS vectorstore for RECIPES_AND_MEALS...\")\n",
    "    vectorstore_recipes = FAISS.from_documents(\n",
    "        documents=recipes_and_meals_docs,\n",
    "        embedding=embeddings,\n",
    "        distance_strategy=DistanceStrategy.COSINE\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ”§ Creating FAISS vectorstore for NUTRITION_FACTS...\")\n",
    "    vectorstore_nutrition = FAISS.from_documents(\n",
    "        documents=nutrition_facts_docs,\n",
    "        embedding=embeddings,\n",
    "        distance_strategy=DistanceStrategy.COSINE\n",
    "    )\n",
    "    \n",
    "    # Save locally\n",
    "    print(\"\\nğŸ’¾ Saving vectorstores to disk...\")\n",
    "    vectorstore_recipes.save_local(\"../vector_databases/recipes_and_meals_db\")\n",
    "    vectorstore_nutrition.save_local(\"../vector_databases/nutrition_facts_db\")\n",
    "    \n",
    "    print(\"\\nâœ… Collections built and saved successfully!\")\n",
    "    \n",
    "    return vectorstore_recipes, vectorstore_nutrition\n",
    "\n",
    "# Build the collections\n",
    "vectorstore_recipes, vectorstore_nutrition = build_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ddcb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading embedding model...\n",
      "ğŸ“‚ Loading RECIPES_AND_MEALS vectorstore from disk...\n",
      "ğŸ“‚ Loading NUTRITION_FACTS vectorstore from disk...\n",
      "âœ… Vectorstores loaded successfully!\n",
      "   - RECIPES_AND_MEALS: 5090 vectors\n",
      "   - NUTRITION_FACTS: 8789 vectors\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ RAG System Ready! Test it below:\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Load Existing Vectorstores & Setup Retrieval\n",
    "# ========================================\n",
    "\n",
    "def load_existing_vectorstores():\n",
    "    \"\"\"\n",
    "    Load pre-built vectorstores from disk (NO re-embedding needed!)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Loading embedding model...\")\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ“‚ Loading RECIPES_AND_MEALS vectorstore from disk...\")\n",
    "    vectorstore_recipes = FAISS.load_local(\n",
    "        folder_path=\"../vector_databases/recipes_and_meals_db\",\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True  # Required for loading pickled data\n",
    "    )\n",
    "    \n",
    "    print(\"ğŸ“‚ Loading NUTRITION_FACTS vectorstore from disk...\")\n",
    "    vectorstore_nutrition = FAISS.load_local(\n",
    "        folder_path=\"../vector_databases/nutrition_facts_db\",\n",
    "        embeddings=embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Vectorstores loaded successfully!\")\n",
    "    print(f\"   - RECIPES_AND_MEALS: {vectorstore_recipes.index.ntotal} vectors\")\n",
    "    print(f\"   - NUTRITION_FACTS: {vectorstore_nutrition.index.ntotal} vectors\")\n",
    "    \n",
    "    return vectorstore_recipes, vectorstore_nutrition\n",
    "\n",
    "\n",
    "def determine_query_type(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Intelligently route queries to the right collection\n",
    "    \n",
    "    Returns: 'recipes', 'nutrition', or 'both'\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Keywords for each collection\n",
    "    recipe_keywords = [\n",
    "        'recipe', 'meal', 'cook', 'prepare', 'make', 'dish', \n",
    "        'breakfast', 'lunch', 'dinner', 'snack',\n",
    "        'vegetarian', 'vegan', 'keto', 'paleo',\n",
    "        'cuisine', 'italian', 'chinese', 'indian'\n",
    "    ]\n",
    "    \n",
    "    nutrition_keywords = [\n",
    "        'nutrition', 'nutrient', 'vitamin', 'mineral', \n",
    "        'calorie', 'protein', 'carb', 'fat', 'fiber',\n",
    "        'healthy', 'good source', 'rich in',\n",
    "        'ingredient', 'food'\n",
    "    ]\n",
    "    \n",
    "    # Check for recipe keywords\n",
    "    recipe_match = any(keyword in query_lower for keyword in recipe_keywords)\n",
    "    \n",
    "    # Check for nutrition keywords\n",
    "    nutrition_match = any(keyword in query_lower for keyword in nutrition_keywords)\n",
    "    \n",
    "    # Routing logic\n",
    "    if recipe_match and not nutrition_match:\n",
    "        return 'recipes'\n",
    "    elif nutrition_match and not recipe_match:\n",
    "        return 'nutrition'\n",
    "    else:\n",
    "        return 'both'  # Search both when ambiguous\n",
    "\n",
    "\n",
    "def smart_retrieve(query: str, vectorstore_recipes, vectorstore_nutrition, k: int = 10) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Smart retrieval across collections based on query type\n",
    "    \"\"\"\n",
    "    query_type = determine_query_type(query)\n",
    "    \n",
    "    print(f\"ğŸ” Query type detected: {query_type.upper()}\")\n",
    "    \n",
    "    if query_type == 'recipes':\n",
    "        # Search only recipes\n",
    "        results = vectorstore_recipes.similarity_search(query, k=k)\n",
    "        print(f\"   â†’ Searched RECIPES_AND_MEALS collection\")\n",
    "        \n",
    "    elif query_type == 'nutrition':\n",
    "        # Search only nutrition facts\n",
    "        results = vectorstore_nutrition.similarity_search(query, k=k)\n",
    "        print(f\"   â†’ Searched NUTRITION_FACTS collection\")\n",
    "        \n",
    "    else:  # 'both'\n",
    "        # Search both and merge results\n",
    "        results_recipes = vectorstore_recipes.similarity_search(query, k=k//2 + 1)\n",
    "        results_nutrition = vectorstore_nutrition.similarity_search(query, k=k//2 + 1)\n",
    "        results = results_recipes + results_nutrition\n",
    "        print(f\"   â†’ Searched BOTH collections\")\n",
    "    \n",
    "    return results[:k]  # Return top-k overall\n",
    "\n",
    "\n",
    "# Load vectorstores (FAST - no re-embedding!)\n",
    "vectorstore_recipes, vectorstore_nutrition = load_existing_vectorstores()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ RAG System Ready! Test it below:\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7c6e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ TEST 1: Recipe Query\n",
      "Query: 'vegetarian high-protein meal under 500 calories'\n",
      "\n",
      "ğŸ” Query type detected: BOTH\n",
      "   â†’ Searched BOTH collections\n",
      "\n",
      "--- Result 1 ---\n",
      "Type: meal\n",
      "Name: Try Soup\n",
      "Calories: 196 kcal\n",
      "Protein: 74.8g\n",
      "Text preview: Meal: Try Soup (Italian Snack)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 325g serving:\n",
      "- Calories: 196 kcal\n",
      "- Protein: 74.8g | Carbs: 27.2g | Fat: 24.0g\n",
      "- Fiber: 25.7g | Sugar: 18.2g\n",
      "- Sodium: 2467mg | Cho...\n",
      "\n",
      "--- Result 2 ---\n",
      "Type: meal\n",
      "Name: Above Stew\n",
      "Calories: 416 kcal\n",
      "Protein: 22.5g\n",
      "Text preview: Meal: Above Stew (American Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 186g serving:\n",
      "- Calories: 416 kcal\n",
      "- Protein: 22.5g | Carbs: 138.9g | Fat: 3.0g\n",
      "- Fiber: 14.4g | Sugar: 44.5g\n",
      "- Sodium: 1739mg | ...\n",
      "\n",
      "--- Result 3 ---\n",
      "Type: meal\n",
      "Name: Once Rice\n",
      "Calories: 244 kcal\n",
      "Protein: 13.8g\n",
      "Text preview: Meal: Once Rice (American Breakfast)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 265g serving:\n",
      "- Calories: 244 kcal\n",
      "- Protein: 13.8g | Carbs: 36.9g | Fat: 15.3g\n",
      "- Fiber: 4.0g | Sugar: 29.0g\n",
      "- Sodium: 1521mg ...\n",
      "\n",
      "--- Result 4 ---\n",
      "Type: meal\n",
      "Name: Once Wrap\n",
      "Calories: 434 kcal\n",
      "Protein: 51.8g\n",
      "Text preview: Meal: Once Wrap (American Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 361g serving:\n",
      "- Calories: 434 kcal\n",
      "- Protein: 51.8g | Carbs: 7.2g | Fat: 50.8g\n",
      "- Fiber: 14.4g | Sugar: 10.6g\n",
      "- Sodium: 1790mg | Ch...\n",
      "\n",
      "--- Result 5 ---\n",
      "Type: meal\n",
      "Name: Eat Rice\n",
      "Calories: 342 kcal\n",
      "Protein: 72.0g\n",
      "Text preview: Meal: Eat Rice (American Dinner)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 334g serving:\n",
      "- Calories: 342 kcal\n",
      "- Protein: 72.0g | Carbs: 52.2g | Fat: 27.3g\n",
      "- Fiber: 28.8g | Sugar: 12.4g\n",
      "- Sodium: 1899mg | C...\n",
      "\n",
      "--- Result 6 ---\n",
      "Type: meal\n",
      "Name: Base Rice\n",
      "Calories: 356 kcal\n",
      "Protein: 18.8g\n",
      "Text preview: Meal: Base Rice (Chinese Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 126g serving:\n",
      "- Calories: 356 kcal\n",
      "- Protein: 18.8g | Carbs: 48.2g | Fat: 49.3g\n",
      "- Fiber: 27.6g | Sugar: 16.0g\n",
      "- Sodium: 1306mg | Ch...\n",
      "\n",
      "--- Result 7 ---\n",
      "Type: nutrition_fact\n",
      "Name: Vegetarian meatloaf or patties\n",
      "Calories: 197.0 kcal\n",
      "Protein: 21.0g\n",
      "Text preview: Ingredient: Vegetarian meatloaf or patties (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 197 kcal\n",
      "- Protein: 21.00 g\n",
      "- Carbohydrates: 8.00 g\n",
      "- Total Fat: 9g\n",
      "- Fiber: 4.6 g\n",
      "- Sugars: 1.20 g\n",
      "\n",
      "Key Vitamins:\n",
      "-...\n",
      "\n",
      "--- Result 8 ---\n",
      "Type: nutrition_fact\n",
      "Name: MORNINGSTAR FARMS Meal Starters Veggie Meatballs, unprepared, frozen\n",
      "Calories: 158.0 kcal\n",
      "Protein: 17.7g\n",
      "Text preview: Ingredient: MORNINGSTAR FARMS Meal Starters Veggie Meatballs, unprepared, frozen (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 158 kcal\n",
      "- Protein: 17.70 g\n",
      "- Carbohydrates: 9.90 g\n",
      "- Total Fat: 5.8g\n",
      "- Fiber:...\n",
      "\n",
      "--- Result 9 ---\n",
      "Type: nutrition_fact\n",
      "Name: WORTHINGTON Vegetarian Burger, unprepared, canned\n",
      "Calories: 124.0 kcal\n",
      "Protein: 18.6g\n",
      "Text preview: Ingredient: WORTHINGTON Vegetarian Burger, unprepared, canned (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 124 kcal\n",
      "- Protein: 18.60 g\n",
      "- Carbohydrates: 6.20 g\n",
      "- Total Fat: 2.9g\n",
      "- Fiber: 2.7 g\n",
      "- Sugars: 0....\n",
      "\n",
      "--- Result 10 ---\n",
      "Type: nutrition_fact\n",
      "Name: Vegetarian fillets\n",
      "Calories: 290.0 kcal\n",
      "Protein: 23.0g\n",
      "Text preview: Ingredient: Vegetarian fillets (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 290 kcal\n",
      "- Protein: 23.00 g\n",
      "- Carbohydrates: 9.00 g\n",
      "- Total Fat: 18g\n",
      "- Fiber: 6.1 g\n",
      "- Sugars: 0.80 g\n",
      "\n",
      "Key Vitamins:\n",
      "- Vitamin A:...\n",
      "\n",
      "\n",
      "ğŸ“ TEST 2: Nutrition Query\n",
      "Query: 'what foods are high in vitamin C?'\n",
      "\n",
      "ğŸ” Query type detected: NUTRITION\n",
      "   â†’ Searched NUTRITION_FACTS collection\n",
      "\n",
      "--- Result 1 ---\n",
      "Type: nutrition_fact\n",
      "Food: Beverages, high vitamin C, greater than 3% juice, fruit juice drink\n",
      "Text preview: Ingredient: Beverages, high vitamin C, greater than 3% juice, fruit juice drink (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 46 kcal\n",
      "- Protein: 0.13 g\n",
      "- Carbohydrates: 11.35 g\n",
      "- Total Fat: 0.1g\n",
      "- Fiber: 0...\n",
      "\n",
      "--- Result 2 ---\n",
      "Type: nutrition_fact\n",
      "Food: Ruby Red grapefruit juice blend (grapefruit, grape, apple), with added vitamin C, bottled, OCEAN SPRAY\n",
      "Text preview: Ingredient: Ruby Red grapefruit juice blend (grapefruit, grape, apple), with added vitamin C, bottled, OCEAN SPRAY (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 44 kcal\n",
      "- Protein: 0.50 g\n",
      "- Carbohydrates: 1...\n",
      "\n",
      "--- Result 3 ---\n",
      "Type: nutrition_fact\n",
      "Food: Beverages, with high vitamin C, Fruit flavored drink containing less than 3% fruit juice\n",
      "Text preview: Ingredient: Beverages, with high vitamin C, Fruit flavored drink containing less than 3% fruit juice (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 27 kcal\n",
      "- Protein: 0.00 g\n",
      "- Carbohydrates: 6.67 g\n",
      "- Total ...\n",
      "\n",
      "--- Result 4 ---\n",
      "Type: nutrition_fact\n",
      "Food: Candies, with high vitamin C, fruit snacks\n",
      "Text preview: Ingredient: Candies, with high vitamin C, fruit snacks (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 352 kcal\n",
      "- Protein: 0.08 g\n",
      "- Carbohydrates: 87.97 g\n",
      "- Total Fat: 0g\n",
      "- Fiber: 0.0 g\n",
      "- Sugars: 68.18 g\n",
      "\n",
      "Ke...\n",
      "\n",
      "--- Result 5 ---\n",
      "Type: nutrition_fact\n",
      "Food: Juice, with added ascorbic acid, apple and grape blend\n",
      "Text preview: Ingredient: Juice, with added ascorbic acid, apple and grape blend (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 50 kcal\n",
      "- Protein: 0.16 g\n",
      "- Carbohydrates: 12.46 g\n",
      "- Total Fat: 0.1g\n",
      "- Fiber: 0.2 g\n",
      "- Sugars...\n",
      "\n",
      "--- Result 6 ---\n",
      "Type: nutrition_fact\n",
      "Food: Beverages, not fortified with vitamin C, less than 3% juice, Fruit flavored drink\n",
      "Text preview: Ingredient: Beverages, not fortified with vitamin C, less than 3% juice, Fruit flavored drink (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 64 kcal\n",
      "- Protein: 0.00 g\n",
      "- Carbohydrates: 16.03 g\n",
      "- Total Fat: 0...\n",
      "\n",
      "--- Result 7 ---\n",
      "Type: nutrition_fact\n",
      "Food: Beverages, added vitamin C, with low-calorie sweetener, reduced calorie, Vegetable and fruit juice drink\n",
      "Text preview: Ingredient: Beverages, added vitamin C, with low-calorie sweetener, reduced calorie, Vegetable and fruit juice drink (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 4 kcal\n",
      "- Protein: 0.00 g\n",
      "- Carbohydrates: ...\n",
      "\n",
      "--- Result 8 ---\n",
      "Type: nutrition_fact\n",
      "Food: Snacks, yogurt covered with vitamin C, candy bits\n",
      "Text preview: Ingredient: Snacks, yogurt covered with vitamin C, candy bits (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 415 kcal\n",
      "- Protein: 0.00 g\n",
      "- Carbohydrates: 86.90 g\n",
      "- Total Fat: 7.5g\n",
      "- Fiber: 0.2 g\n",
      "- Sugars: 65...\n",
      "\n",
      "--- Result 9 ---\n",
      "Type: nutrition_fact\n",
      "Food: Grape juice, with added ascorbic acid, unsweetened, canned or bottled\n",
      "Text preview: Ingredient: Grape juice, with added ascorbic acid, unsweetened, canned or bottled (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 60 kcal\n",
      "- Protein: 0.37 g\n",
      "- Carbohydrates: 14.77 g\n",
      "- Total Fat: 0.1g\n",
      "- Fiber:...\n",
      "\n",
      "--- Result 10 ---\n",
      "Type: nutrition_fact\n",
      "Food: Grape juice, with added ascorbic acid and calcium, unsweetened, canned or bottled\n",
      "Text preview: Ingredient: Grape juice, with added ascorbic acid and calcium, unsweetened, canned or bottled (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 62 kcal\n",
      "- Protein: 0.37 g\n",
      "- Carbohydrates: 14.77 g\n",
      "- Total Fat: 0...\n",
      "\n",
      "\n",
      "ğŸ“ TEST 3: Mixed Query\n",
      "Query: 'low-carb chicken recipe with good protein'\n",
      "\n",
      "ğŸ” Query type detected: BOTH\n",
      "   â†’ Searched BOTH collections\n",
      "\n",
      "--- Result 1 ---\n",
      "Type: recipe\n",
      "Name: Quick and Easy Chicken\n",
      "Text preview: Recipe: Quick and Easy Chicken\n",
      "Cuisine: /Meat and Poultry/Chicken/Chicken Breast/Skillet Chicken/\n",
      "Ingredients:\n",
      "2 tablespoons olive oil, 1  onion, chop...\n",
      "\n",
      "--- Result 2 ---\n",
      "Type: recipe\n",
      "Name: Chicken Meatloaf\n",
      "Text preview: Recipe: Chicken Meatloaf\n",
      "Ingredients:\n",
      "- 2 lbs ground chicken\n",
      "- 1 (6 ounce) box Stove Top stuffing mix (any flavour)\n",
      "- 1/2 cup parmesan cheese\n",
      "- 2 cups...\n",
      "\n",
      "--- Result 3 ---\n",
      "Type: recipe\n",
      "Name: Hawaiian Chicken Kabobs\n",
      "Text preview: Recipe: Hawaiian Chicken Kabobs\n",
      "Cuisine: /Meat and Poultry/Chicken/Chicken Breast/Healthy Chicken/\n",
      "Ingredients:\n",
      "3 tablespoons soy sauce, 3 tablespoons...\n",
      "\n",
      "--- Result 4 ---\n",
      "Type: recipe\n",
      "Name: Sweet and Sour Chicken III\n",
      "Text preview: Recipe: Sweet and Sour Chicken III\n",
      "Cuisine: /Cuisine/Asian/\n",
      "Ingredients:\n",
      "1 pound skinless, boneless chicken breast meat - cubed, 2 tablespoons vegetab...\n",
      "\n",
      "--- Result 5 ---\n",
      "Type: recipe\n",
      "Name: Ww Chicken and Pasta\n",
      "Text preview: Recipe: Ww Chicken and Pasta\n",
      "Ingredients:\n",
      "- 34 lb whole wheat pasta (I used fusilli)\n",
      "- 3 (1/4 lb) boneless skinless chicken breast\n",
      "- 34 teaspoon salt\n",
      "...\n",
      "\n",
      "--- Result 6 ---\n",
      "Type: meal\n",
      "Name: Try Rice\n",
      "Text preview: Meal: Try Rice (Indian Breakfast)\n",
      "Diet Type: Low-Carb\n",
      "\n",
      "Nutrition per 308g serving:\n",
      "- Calories: 407 kcal\n",
      "- Protein: 78.2g | Carbs: 17.3g | Fat: 44.9g\n",
      "-...\n",
      "\n",
      "--- Result 7 ---\n",
      "Type: nutrition_fact\n",
      "Name: SUPPER BAKES MEAL KITS, Southwestern-Style Chicken w/rice (chicken not included)\n",
      "Text preview: Ingredient: SUPPER BAKES MEAL KITS, Southwestern-Style Chicken w/rice (chicken not included) (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 189 kcal\n",
      "- Prote...\n",
      "\n",
      "--- Result 8 ---\n",
      "Type: nutrition_fact\n",
      "Name: SUPPER BAKES MEAL KITS, Cheesy Chicken with pasta (chicken not included)\n",
      "Text preview: Ingredient: SUPPER BAKES MEAL KITS, Cheesy Chicken with pasta (chicken not included) (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 198 kcal\n",
      "- Protein: 7.06...\n",
      "\n",
      "--- Result 9 ---\n",
      "Type: nutrition_fact\n",
      "Name: SUPPER BAKES MEAL KITS, Traditional Roast Chicken with stuffing (chicken not included)\n",
      "Text preview: Ingredient: SUPPER BAKES MEAL KITS, Traditional Roast Chicken with stuffing (chicken not included) (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 190 kcal\n",
      "-...\n",
      "\n",
      "--- Result 10 ---\n",
      "Type: nutrition_fact\n",
      "Name: Fast foods, plain, boneless pieces, breaded and fried, chicken\n",
      "Text preview: Ingredient: Fast foods, plain, boneless pieces, breaded and fried, chicken (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 307 kcal\n",
      "- Protein: 15.92 g\n",
      "- Carb...\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Test Smart Retrieval\n",
    "# ========================================\n",
    "\n",
    "# Test Query 1: Recipe search\n",
    "print(\"\\nğŸ“ TEST 1: Recipe Query\")\n",
    "print(\"Query: 'vegetarian high-protein meal under 500 calories'\\n\")\n",
    "\n",
    "results1 = smart_retrieve(\n",
    "    query=\"vegetarian high-protein meal under 500 calories\",\n",
    "    vectorstore_recipes=vectorstore_recipes,\n",
    "    vectorstore_nutrition=vectorstore_nutrition,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(results1, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Type: {doc.metadata.get('doc_type')}\")\n",
    "    print(f\"Name: {doc.metadata.get('recipe_name', doc.metadata.get('food_name'))}\")\n",
    "    if 'calories' in doc.metadata:\n",
    "        print(f\"Calories: {doc.metadata['calories']} kcal\")\n",
    "    if 'protein_g' in doc.metadata:\n",
    "        print(f\"Protein: {doc.metadata['protein_g']}g\")\n",
    "    print(f\"Text preview: {doc.page_content[:200]}...\")\n",
    "\n",
    "\n",
    "# Test Query 2: Nutrition search\n",
    "print(\"\\n\\nğŸ“ TEST 2: Nutrition Query\")\n",
    "print(\"Query: 'what foods are high in vitamin C?'\\n\")\n",
    "\n",
    "results2 = smart_retrieve(\n",
    "    query=\"what foods are high in vitamin C?\",\n",
    "    vectorstore_recipes=vectorstore_recipes,\n",
    "    vectorstore_nutrition=vectorstore_nutrition,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(results2, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Type: {doc.metadata.get('doc_type')}\")\n",
    "    print(f\"Food: {doc.metadata.get('food_name', doc.metadata.get('recipe_name'))}\")\n",
    "    print(f\"Text preview: {doc.page_content[:200]}...\")\n",
    "\n",
    "\n",
    "# Test Query 3: Mixed search\n",
    "print(\"\\n\\nğŸ“ TEST 3: Mixed Query\")\n",
    "print(\"Query: 'low-carb chicken recipe with good protein'\\n\")\n",
    "\n",
    "results3 = smart_retrieve(\n",
    "    query=\"low-carb chicken recipe with good protein\",\n",
    "    vectorstore_recipes=vectorstore_recipes,\n",
    "    vectorstore_nutrition=vectorstore_nutrition,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(results3, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Type: {doc.metadata.get('doc_type')}\")\n",
    "    print(f\"Name: {doc.metadata.get('recipe_name', doc.metadata.get('food_name'))}\")\n",
    "    print(f\"Text preview: {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41b52194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Initializing Ollama LLM (llama3.2)...\n",
      "ğŸ”Œ Testing LLM connection...\n",
      "âœ… LLM Response: Connection successful!...\n",
      "\n",
      "ğŸ”— Creating Smart Retriever...\n",
      "ğŸ“ Creating Prompt Template...\n",
      "ğŸ”§ Creating Stuff Documents Chain...\n",
      "â›“ï¸ Creating Retrieval Chain...\n",
      "\n",
      "============================================================\n",
      "âœ… RAG CHAIN READY!\n",
      "============================================================\n",
      "Components:\n",
      "  ğŸ¤– LLM: Ollama llama3.2\n",
      "  ğŸ” Retriever: Smart Dual-Collection Retriever\n",
      "  ğŸ“ Prompt: NutriGuide System Prompt\n",
      "  â›“ï¸ Chain: Retrieval Chain (RAG)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# System Prompt + Ollama LLM + RAG Chain\n",
    "# ========================================\n",
    "\n",
    "# NutriGuide System Prompt - Comprehensive instruction set for the AI assistant\n",
    "SYSTEM_PROMPT = \"\"\"You are NutriGuide, an AI nutrition assistant providing personalized recipe recommendations.\n",
    "\n",
    "## CRITICAL SAFETY DISCLAIMER\n",
    "You are a recommendation system ONLY. Your suggestions do NOT replace professional medical advice from healthcare providers.\n",
    "\n",
    "## STRICT OUTPUT REQUIREMENTS\n",
    "\n",
    "For EVERY recipe recommendation, you MUST include ALL of the following sections in this exact order:\n",
    "\n",
    "### MANDATORY SECTIONS (DO NOT SKIP ANY):\n",
    "\n",
    "**1. Recipe Name** (Adapted if modified)\n",
    "\n",
    "**2. Why This Recipe:**\n",
    "- Meets calorie/protein requirements\n",
    "- Dietary compliance (vegetarian, vegan, etc.)\n",
    "- Medical alignment (if applicable)\n",
    "\n",
    "**3. Adaptations Made:** (if any)\n",
    "- State \"No adaptations needed\" if recipe matches perfectly\n",
    "- OR list: Original â†’ Modified â†’ Reason\n",
    "\n",
    "**4. Nutritional Information (per serving):**\n",
    "- Calories: X kcal\n",
    "- Protein: X g\n",
    "- Carbohydrates: X g  \n",
    "- Fat: X g\n",
    "- Fiber: X g (if relevant)\n",
    "- Sodium: X mg (if relevant)\n",
    "\n",
    "**5. Ingredients (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and list ingredients from the retrieved context.**\n",
    "**If ingredient quantities are missing in context, you MUST:**\n",
    "- Estimate reasonable quantities based on the serving size\n",
    "- Mark estimates with (approximately)\n",
    "- Convert ALL measurements to metric: grams (g), milliliters (ml)\n",
    "- Format: `- XXXg ingredient name` or `- XXml liquid name`\n",
    "\n",
    "Example format:\n",
    "```\n",
    "Ingredients:\n",
    "- 200g vegetarian meatballs\n",
    "- 400ml vegetable broth\n",
    "- 150g spinach (approximately, adjusted for serving)\n",
    "- 100g tomatoes\n",
    "- 15ml olive oil\n",
    "- 5g salt\n",
    "```\n",
    "\n",
    "**6. Cooking Instructions (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and provide step-by-step instructions from the retrieved context.**\n",
    "**If instructions are missing, you MUST:**\n",
    "- Create logical cooking steps based on the ingredients\n",
    "- Include temperatures in Celsius (Â°C)\n",
    "- Number each step clearly\n",
    "\n",
    "Example format:\n",
    "```\n",
    "Cooking Instructions:\n",
    "1. Preheat oven to 180Â°C\n",
    "2. Heat 15ml olive oil in a large pot over medium heat\n",
    "3. Add 200g meatballs and cook for 5-7 minutes until browned\n",
    "4. Add 400ml broth and 100g tomatoes, bring to simmer\n",
    "5. Add 150g spinach, cook for 3-4 minutes until wilted\n",
    "6. Season with 5g salt, serve hot\n",
    "```\n",
    "\n",
    "**7. Time Information:**\n",
    "- Preparation Time: X minutes\n",
    "- Cooking Time: X minutes  \n",
    "- Total Time: X minutes\n",
    "\n",
    "---\n",
    "\n",
    "## HANDLING MISSING DATA\n",
    "\n",
    "**If retrieved context lacks ingredient quantities:**\n",
    "â†’ You MUST estimate based on:\n",
    "- Serving size (e.g., 325g serving = ~300-350g total ingredients)\n",
    "- Standard recipe proportions\n",
    "- Mark as \"(approximately)\" or \"(estimated for 1 serving)\"\n",
    "\n",
    "**If retrieved context lacks cooking instructions:**\n",
    "â†’ You MUST create logical steps based on:\n",
    "- Ingredient types (raw â†’ needs cooking)\n",
    "- Preparation method stated (Baked, Fried, Raw, etc.)\n",
    "- Standard cooking techniques\n",
    "\n",
    "**NEVER say:** \"Cooking instructions not available in database\"  \n",
    "**ALWAYS provide:** Complete, usable recipe instructions\n",
    "\n",
    "---\n",
    "\n",
    "## MEASUREMENT CONVERSIONS (STRICT)\n",
    "\n",
    "**Convert ALL measurements to metric:**\n",
    "- 1 cup â†’ 240 ml\n",
    "- 1 tbsp â†’ 15 ml\n",
    "- 1 tsp â†’ 5 ml\n",
    "- 1 oz â†’ 28 g\n",
    "- 1 lb â†’ 454 g\n",
    "\n",
    "**Temperatures MUST be Celsius:**\n",
    "- 350Â°F â†’ 175Â°C\n",
    "- 400Â°F â†’ 200Â°C\n",
    "\n",
    "---\n",
    "\n",
    "## EXAMPLE COMPLETE OUTPUT\n",
    "\n",
    "**Recipe 1: High-Protein Veggie Soup (Adapted)**\n",
    "\n",
    "**Why This Recipe:**\n",
    "Meets your 500 kcal limit (320 kcal) with exceptional protein content (44.8g). Vegetarian and includes nutrient-dense ingredients.\n",
    "\n",
    "**Adaptations Made:**\n",
    "- Added MORNINGSTAR Veggie Meatballs (not in original recipe) â†’ Boosts protein content\n",
    "- Reduced serving size from 325g to 280g â†’ Meets calorie target\n",
    "\n",
    "**Nutritional Information (per serving):**\n",
    "- Calories: 320 kcal\n",
    "- Protein: 44.8g\n",
    "- Carbohydrates: 25.2g\n",
    "- Fat: 15.6g\n",
    "- Fiber: 9.4g\n",
    "- Sodium: 1800mg\n",
    "\n",
    "**Ingredients:**\n",
    "- 200g MORNINGSTAR Veggie Meatballs (frozen, unprepared)\n",
    "- 400ml vegetable broth\n",
    "- 150g spinach (approximately)\n",
    "- 100g diced tomatoes\n",
    "- 50g carrots (approximately)\n",
    "- 15ml olive oil\n",
    "- 5g salt\n",
    "- 2g black pepper\n",
    "\n",
    "**Cooking Instructions:**\n",
    "1. Heat 15ml olive oil in a large pot over medium heat\n",
    "2. Add 200g veggie meatballs and cook for 5-7 minutes until browned\n",
    "3. Add 400ml vegetable broth and bring to a boil\n",
    "4. Add 100g tomatoes and 50g carrots, reduce heat and simmer for 15 minutes\n",
    "5. Add 150g spinach and cook for 3-4 minutes until wilted\n",
    "6. Season with 5g salt and 2g pepper\n",
    "7. Serve hot\n",
    "\n",
    "**Preparation Time:** 10 minutes  \n",
    "**Cooking Time:** 25 minutes  \n",
    "**Total Time:** 35 minutes\n",
    "\n",
    "---\n",
    "\n",
    "[Repeat exact structure for Recipe 2 and Recipe 3]\n",
    "\n",
    "---\n",
    "\n",
    "âš ï¸ **Important Reminder**: These are suggestions based on general nutrition principles. Consult healthcare providers before dietary changes.\n",
    "\n",
    "---\n",
    "\n",
    "## YOUR TASK NOW:\n",
    "\n",
    "User Query: {input}\n",
    "\n",
    "Retrieved Context: {context}\n",
    "\n",
    "Generate 3 complete recipe recommendations following the MANDATORY SECTIONS structure above.\n",
    "**DO NOT skip Ingredients or Cooking Instructions sections.**\n",
    "**If data is missing, estimate based on serving size and recipe type.**\"\"\"\n",
    "\n",
    "\n",
    "# Initialize Ollama LLM with optimal configuration\n",
    "print(\"ğŸ¤– Initializing Ollama LLM (llama3.2)...\")\n",
    "llm = OllamaLLM(\n",
    "    model=\"llama3.2\", # Change to your preferred model (llama3.2, llama3.1, mistral, etc.)\n",
    "    temperature=0.5, # Creativity level (0=deterministic, 1=creative)\n",
    "    base_url=\"http://localhost:11434/\" # Default Ollama URL\n",
    ")\n",
    "\n",
    "# Verify LLM connectivity\n",
    "print(\"ğŸ”Œ Testing LLM connection...\")\n",
    "try:\n",
    "    test_response = llm.invoke(\"Say 'Connection successful!' if you can read this.\")\n",
    "    print(f\"âœ… LLM Response: {test_response[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ LLM Connection Error: {e}\")\n",
    "    print(\"âš ï¸ Make sure Ollama is running: 'ollama serve'\")\n",
    "\n",
    "\n",
    "# Import required LangChain components\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "class SmartRetriever(Runnable):\n",
    "    \"\"\"\n",
    "    Intelligent retriever that routes queries to appropriate vector collections.\n",
    "    Implements LangChain's Runnable interface for seamless chain integration.\n",
    "    \n",
    "    Routes queries to:\n",
    "    - RECIPES_AND_MEALS: Recipe and meal recommendations\n",
    "    - NUTRITION_FACTS: Ingredient-level nutritional data\n",
    "    - BOTH: Complex queries requiring comprehensive context\n",
    "    \"\"\"\n",
    "    def __init__(self, vectorstore_recipes, vectorstore_nutrition, k=10):\n",
    "        self.vectorstore_recipes = vectorstore_recipes\n",
    "        self.vectorstore_nutrition = vectorstore_nutrition\n",
    "        self.k = k\n",
    "    \n",
    "    def invoke(self, input: dict | str, config: RunnableConfig = None) -> List[Document]:\n",
    "        \"\"\"Execute smart retrieval based on query analysis\"\"\"\n",
    "        # Handle both dict and string inputs\n",
    "        if isinstance(input, dict):\n",
    "            query = input.get(\"input\", \"\")\n",
    "        else:\n",
    "            query = input\n",
    "            \n",
    "        return smart_retrieve(\n",
    "            query=query,\n",
    "            vectorstore_recipes=self.vectorstore_recipes,\n",
    "            vectorstore_nutrition=self.vectorstore_nutrition,\n",
    "            k=self.k\n",
    "        )\n",
    "\n",
    "\n",
    "# Initialize retriever with loaded vectorstores\n",
    "print(\"\\nğŸ”— Creating Smart Retriever...\")\n",
    "smart_retriever = SmartRetriever(\n",
    "    vectorstore_recipes=vectorstore_recipes,\n",
    "    vectorstore_nutrition=vectorstore_nutrition,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "\n",
    "# Configure prompt template with system instructions\n",
    "print(\"ğŸ“ Creating Prompt Template...\")\n",
    "prompt_template = ChatPromptTemplate.from_template(SYSTEM_PROMPT)\n",
    "\n",
    "\n",
    "# Build document processing chain\n",
    "print(\"ğŸ”§ Creating Stuff Documents Chain...\")\n",
    "stuff_documents_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "\n",
    "# Assemble complete RAG pipeline\n",
    "print(\"â›“ï¸ Creating Retrieval Chain...\")\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=smart_retriever,\n",
    "    combine_docs_chain=stuff_documents_chain\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… RAG CHAIN READY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Components:\")\n",
    "print(\"  ğŸ¤– LLM: Ollama llama3.2\")\n",
    "print(\"  ğŸ” Retriever: Smart Dual-Collection Retriever\")\n",
    "print(\"  ğŸ“ Prompt: NutriGuide System Prompt\")\n",
    "print(\"  â›“ï¸ Chain: Retrieval Chain (RAG)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a6f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing RAG System\n",
      "\n",
      "Query: I need a vegetarian high-protein meal under 500 calories. What do you recommend?\n",
      "\n",
      "============================================================\n",
      "ğŸ” Query type detected: BOTH\n",
      "   â†’ Searched BOTH collections\n",
      "Here are three complete recipe recommendations following the MANDATORY SECTIONS structure:\n",
      "\n",
      "**Recipe 1: High-Protein Veggie Soup (Adapted)**\n",
      "\n",
      "**Why This Recipe:**\n",
      "Meets your 500 kcal limit with exceptional protein content (44.8g). Vegetarian and includes nutrient-dense ingredients.\n",
      "\n",
      "**Adaptations Made:**\n",
      "- Added MORNINGSTAR Veggie Meatballs (not in original recipe) â†’ Boosts protein content\n",
      "- Reduced serving size from 325g to 280g â†’ Meets calorie target\n",
      "\n",
      "**Nutritional Information (per serving):**\n",
      "- Calories: 320 kcal\n",
      "- Protein: 44.8g\n",
      "- Carbohydrates: 25.2g\n",
      "- Fat: 15.6g\n",
      "- Fiber: 9.4g\n",
      "- Sodium: 1800mg\n",
      "\n",
      "**Ingredients:**\n",
      "- 200g MORNINGSTAR Veggie Meatballs (frozen, unprepared)\n",
      "- 400ml vegetable broth\n",
      "- 150g spinach (approximately)\n",
      "- 100g diced tomatoes\n",
      "- 50g carrots (approximately)\n",
      "- 15ml olive oil\n",
      "- 5g salt\n",
      "- 2g black pepper\n",
      "\n",
      "**Cooking Instructions:**\n",
      "1. Heat 15ml olive oil in a large pot over medium heat\n",
      "2. Add 200g veggie meatballs and cook for 5-7 minutes until browned\n",
      "3. Add 400ml vegetable broth and bring to a boil\n",
      "4. Add 100g tomatoes and 50g carrots, reduce heat and simmer for 15 minutes\n",
      "5. Add 150g spinach and cook for 3-4 minutes until wilted\n",
      "6. Season with 5g salt and 2g pepper\n",
      "7. Serve hot\n",
      "\n",
      "**Preparation Time:** 10 minutes  \n",
      "**Cooking Time:** 25 minutes  \n",
      "**Total Time:** 35 minutes\n",
      "\n",
      "---\n",
      "\n",
      "**Recipe 2: Quinoa Stuffed Bell Peppers (Modified)**\n",
      "\n",
      "**Why This Recipe:**\n",
      "Meets your 400 kcal limit with excellent protein content (22g). Vegetarian and includes nutrient-dense ingredients.\n",
      "\n",
      "**Adaptations Made:**\n",
      "- Reduced quinoa serving size from 250g to 200g â†’ Meets calorie target\n",
      "- Added black beans for extra fiber and protein\n",
      "\n",
      "**Nutritional Information (per serving):**\n",
      "- Calories: 380 kcal\n",
      "- Protein: 22g\n",
      "- Carbohydrates: 30.2g\n",
      "- Fat: 15.8g\n",
      "- Fiber: 10.4g\n",
      "- Sodium: 1200mg\n",
      "\n",
      "**Ingredients:**\n",
      "- 200g quinoa, rinsed and drained\n",
      "- 400ml vegetable broth\n",
      "- 150g black beans (canned)\n",
      "- 100g diced tomatoes\n",
      "- 50g chopped bell peppers\n",
      "- 15ml olive oil\n",
      "- 5g salt\n",
      "- 2g black pepper\n",
      "\n",
      "**Cooking Instructions:**\n",
      "1. Preheat oven to 180Â°C\n",
      "2. Cook quinoa according to package instructions using 400ml vegetable broth\n",
      "3. In a separate pan, heat 15ml olive oil and sautÃ© chopped bell peppers until tender\n",
      "4. Add 150g black beans, 100g diced tomatoes, and cooked quinoa to the pan\n",
      "5. Season with 5g salt and 2g pepper\n",
      "6. Stuff each bell pepper with the quinoa mixture and bake for 20-25 minutes\n",
      "\n",
      "**Preparation Time:** 15 minutes  \n",
      "**Cooking Time:** 25 minutes  \n",
      "**Total Time:** 40 minutes\n",
      "\n",
      "---\n",
      "\n",
      "**Recipe 3: Spinach and Feta Stuffed Portobello Mushrooms (Modified)**\n",
      "\n",
      "**Why This Recipe:**\n",
      "Meets your 450 kcal limit with excellent protein content (30g). Vegetarian and includes nutrient-dense ingredients.\n",
      "\n",
      "**Adaptations Made:**\n",
      "- Reduced feta cheese serving size from 50g to 25g â†’ Meets calorie target\n",
      "- Added chopped spinach for extra fiber and nutrients\n",
      "\n",
      "**Nutritional Information (per serving):**\n",
      "- Calories: 420 kcal\n",
      "- Protein: 30g\n",
      "- Carbohydrates: 20.2g\n",
      "- Fat: 28.8g\n",
      "- Fiber: 6.4g\n",
      "- Sodium: 1500mg\n",
      "\n",
      "**Ingredients:**\n",
      "- 200g portobello mushrooms, stems removed and caps cleaned\n",
      "- 400ml vegetable broth\n",
      "- 100g chopped spinach (fresh)\n",
      "- 25g feta cheese (crumbled)\n",
      "- 15ml olive oil\n",
      "- 5g salt\n",
      "- 2g black pepper\n",
      "\n",
      "**Cooking Instructions:**\n",
      "1. Preheat oven to 180Â°C\n",
      "2. In a pan, heat 15ml olive oil and sautÃ© chopped spinach until wilted\n",
      "3. Add 25g feta cheese and stir until melted\n",
      "4. Stuff each mushroom cap with the spinach-feta mixture and bake for 20-25 minutes\n",
      "\n",
      "**Preparation Time:** 10 minutes  \n",
      "**Cooking Time:** 25 minutes  \n",
      "**Total Time:** 35 minutes\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Interactive Chat Function\n",
    "# ========================================\n",
    "\n",
    "def chat_with_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a query to the RAG system and get NutriGuide's response.\n",
    "    \n",
    "    Args:\n",
    "        query: User's question or request\n",
    "        \n",
    "    Returns:\n",
    "        AI-generated response from NutriGuide\n",
    "    \"\"\"\n",
    "    response = rag_chain.invoke({\"input\": query})\n",
    "    return response.get(\"answer\", \"No response generated.\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# Test RAG System\n",
    "# ========================================\n",
    "\n",
    "# Test query\n",
    "test_query = \"I need a vegetarian high-protein meal under 500 calories. What do you recommend?\"\n",
    "\n",
    "print(\"ğŸ§ª Testing RAG System\\n\")\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = chat_with_rag(test_query)\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338e5bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RecipesNutritionRAG class defined!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RecipesNutritionRAG Class - Production Ready\n",
    "# ========================================\n",
    "\n",
    "# Additional imports for the class\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import ast\n",
    "import re\n",
    "\n",
    "class RecipesNutritionRAG:\n",
    "    \"\"\"\n",
    "    Production-ready RAG system for personalized recipe recommendations.\n",
    "    \n",
    "    Features:\n",
    "    - Dual vectorstore system (recipes + nutrition facts)\n",
    "    - Smart query routing (recipes/nutrition/both)\n",
    "    - Intelligent retrieval with k=10\n",
    "    - Medical-grade system prompt with full recipe structure\n",
    "    - Auto-detects and loads/builds vectorstores\n",
    "    \n",
    "    Usage:\n",
    "        # Initialize\n",
    "        rag = RecipesNutritionRAG(\n",
    "            data_folder=\"../data/\",\n",
    "            vectorstore_path=\"../vector_databases/\",\n",
    "            model_name=\"llama3.2\",\n",
    "            temperature=0.5,\n",
    "            k=10\n",
    "        )\n",
    "        \n",
    "        # Setup (loads or builds vectorstores)\n",
    "        rag.initialize(force_rebuild=False)\n",
    "        \n",
    "        # Query\n",
    "        response = rag.query(\"vegetarian high-protein meal under 500 calories\")\n",
    "        \n",
    "        # Debug\n",
    "        docs = rag.get_retrieved_docs(\"vegetarian meal\")\n",
    "        stats = rag.get_stats()\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========================================\n",
    "    # System Prompt (Fixed - Part of Class)\n",
    "    # ========================================\n",
    "    SYSTEM_PROMPT = \"\"\"You are NutriGuide, an AI nutrition assistant providing personalized recipe recommendations.\n",
    "\n",
    "## CRITICAL SAFETY DISCLAIMER\n",
    "You are a recommendation system ONLY. Your suggestions do NOT replace professional medical advice from healthcare providers.\n",
    "\n",
    "## STRICT OUTPUT REQUIREMENTS\n",
    "\n",
    "For EVERY recipe recommendation, you MUST include ALL of the following sections in this exact order:\n",
    "\n",
    "### MANDATORY SECTIONS (DO NOT SKIP ANY):\n",
    "\n",
    "**1. Recipe Name** (Adapted if modified)\n",
    "\n",
    "**2. Why This Recipe:**\n",
    "- Meets calorie/protein requirements\n",
    "- Dietary compliance (vegetarian, vegan, etc.)\n",
    "- Medical alignment (if applicable)\n",
    "\n",
    "**3. Adaptations Made:** (if any)\n",
    "- State \"No adaptations needed\" if recipe matches perfectly\n",
    "- OR list: Original â†’ Modified â†’ Reason\n",
    "\n",
    "**4. Nutritional Information (per serving):**\n",
    "- Calories: X kcal\n",
    "- Protein: X g\n",
    "- Carbohydrates: X g  \n",
    "- Fat: X g\n",
    "- Fiber: X g (if relevant)\n",
    "- Sodium: X mg (if relevant)\n",
    "\n",
    "**5. Ingredients (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and list ingredients from the retrieved context.**\n",
    "**If ingredient quantities are missing in context, you MUST:**\n",
    "- Estimate reasonable quantities based on the serving size\n",
    "- Mark estimates with (approximately)\n",
    "- Convert ALL measurements to metric: grams (g), milliliters (ml)\n",
    "- Format: `- XXXg ingredient name` or `- XXml liquid name`\n",
    "\n",
    "Example format:\n",
    "```\n",
    "Ingredients:\n",
    "- 200g vegetarian meatballs\n",
    "- 400ml vegetable broth\n",
    "- 150g spinach (approximately, adjusted for serving)\n",
    "- 100g tomatoes\n",
    "- 15ml olive oil\n",
    "- 5g salt\n",
    "```\n",
    "\n",
    "**6. Cooking Instructions (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and provide step-by-step instructions from the retrieved context.**\n",
    "**If instructions are missing, you MUST:**\n",
    "- Create logical cooking steps based on the ingredients\n",
    "- Include temperatures in Celsius (Â°C)\n",
    "- Number each step clearly\n",
    "\n",
    "Example format:\n",
    "```\n",
    "Cooking Instructions:\n",
    "1. Preheat oven to 180Â°C\n",
    "2. Heat 15ml olive oil in a large pot over medium heat\n",
    "3. Add 200g meatballs and cook for 5-7 minutes until browned\n",
    "4. Add 400ml broth and 100g tomatoes, bring to simmer\n",
    "5. Add 150g spinach, cook for 3-4 minutes until wilted\n",
    "6. Season with 5g salt, serve hot\n",
    "```\n",
    "\n",
    "**7. Time Information:**\n",
    "- Preparation Time: X minutes\n",
    "- Cooking Time: X minutes  \n",
    "- Total Time: X minutes\n",
    "\n",
    "---\n",
    "\n",
    "## HANDLING MISSING DATA\n",
    "\n",
    "**If retrieved context lacks ingredient quantities:**\n",
    "â†’ You MUST estimate based on:\n",
    "- Serving size (e.g., 325g serving = ~300-350g total ingredients)\n",
    "- Standard recipe proportions\n",
    "- Mark as \"(approximately)\" or \"(estimated for 1 serving)\"\n",
    "\n",
    "**If retrieved context lacks cooking instructions:**\n",
    "â†’ You MUST create logical steps based on:\n",
    "- Ingredient types (raw â†’ needs cooking)\n",
    "- Preparation method stated (Baked, Fried, Raw, etc.)\n",
    "- Standard cooking techniques\n",
    "\n",
    "**NEVER say:** \"Cooking instructions not available in database\"  \n",
    "**ALWAYS provide:** Complete, usable recipe instructions\n",
    "\n",
    "---\n",
    "\n",
    "## MEASUREMENT CONVERSIONS (STRICT)\n",
    "\n",
    "**Convert ALL measurements to metric:**\n",
    "- 1 cup â†’ 240 ml\n",
    "- 1 tbsp â†’ 15 ml\n",
    "- 1 tsp â†’ 5 ml\n",
    "- 1 oz â†’ 28 g\n",
    "- 1 lb â†’ 454 g\n",
    "\n",
    "**Temperatures MUST be Celsius:**\n",
    "- 350Â°F â†’ 175Â°C\n",
    "- 400Â°F â†’ 200Â°C\n",
    "\n",
    "---\n",
    "\n",
    "## YOUR TASK NOW:\n",
    "\n",
    "User Query: {input}\n",
    "\n",
    "Retrieved Context: {context}\n",
    "\n",
    "Generate 3 complete recipe recommendations following the MANDATORY SECTIONS structure above.\n",
    "**DO NOT skip Ingredients or Cooking Instructions sections.**\n",
    "**If data is missing, estimate based on serving size and recipe type.**\n",
    "\n",
    "âš ï¸ **Important Reminder**: These are suggestions based on general nutrition principles. Consult healthcare providers before dietary changes.\"\"\"\n",
    "    \n",
    "    # ========================================\n",
    "    # Initialization\n",
    "    # ========================================\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_folder: str,\n",
    "        vectorstore_path: str,\n",
    "        model_name: str = \"llama3.2\",\n",
    "        temperature: float = 0.5,\n",
    "        k: int = 10,\n",
    "        ollama_base_url: str = \"http://localhost:11434/\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize RecipesNutritionRAG (does NOT load data yet - call initialize()).\n",
    "        \n",
    "        Args:\n",
    "            data_folder: Path to folder containing CSVs (e.g., \"../data/\")\n",
    "            vectorstore_path: Path to vectorstore folder (e.g., \"../vector_databases/\")\n",
    "            model_name: Ollama model name (default: \"llama3.2\")\n",
    "            temperature: LLM temperature (0=deterministic, 1=creative)\n",
    "            k: Number of documents to retrieve\n",
    "            ollama_base_url: Ollama server URL\n",
    "        \"\"\"\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.vectorstore_path = Path(vectorstore_path)\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.k = k\n",
    "        self.ollama_base_url = ollama_base_url\n",
    "        \n",
    "        # Components (initialized in initialize())\n",
    "        self.embeddings = None\n",
    "        self.vectorstore_recipes = None\n",
    "        self.vectorstore_nutrition = None\n",
    "        self.smart_retriever = None\n",
    "        self.llm = None\n",
    "        self.rag_chain = None\n",
    "        \n",
    "        print(f\"âœ… RecipesNutritionRAG created (NOT initialized yet)\")\n",
    "        print(f\"   Data folder: {self.data_folder}\")\n",
    "        print(f\"   Vectorstore path: {self.vectorstore_path}\")\n",
    "        print(f\"   Model: {self.model_name}\")\n",
    "        print(f\"   Temperature: {self.temperature}\")\n",
    "        print(f\"   k: {self.k}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # Main Setup Method\n",
    "    # ========================================\n",
    "    \n",
    "    def initialize(self, force_rebuild: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the RAG system: load or build vectorstores, create chain.\n",
    "        \n",
    "        Args:\n",
    "            force_rebuild: If True, rebuild vectorstores from CSVs even if they exist\n",
    "        \n",
    "        Flow:\n",
    "            1. Initialize embeddings\n",
    "            2. Check if vectorstores exist\n",
    "            3. If exist AND not force_rebuild â†’ load from disk\n",
    "            4. If not exist OR force_rebuild â†’ build from CSVs\n",
    "            5. Create SmartRetriever\n",
    "            6. Initialize LLM\n",
    "            7. Build RAG chain\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸš€ INITIALIZING RecipesNutritionRAG\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Initialize embeddings\n",
    "        print(\"\\n[1/7] Initializing embedding model...\")\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "            encode_kwargs={\"normalize_embeddings\": True}\n",
    "        )\n",
    "        print(\"âœ… Embeddings ready\")\n",
    "        \n",
    "        # Step 2: Check vectorstore existence\n",
    "        recipes_db_path = self.vectorstore_path / \"recipes_and_meals_db\"\n",
    "        nutrition_db_path = self.vectorstore_path / \"nutrition_facts_db\"\n",
    "        \n",
    "        vectorstores_exist = recipes_db_path.exists() and nutrition_db_path.exists()\n",
    "        \n",
    "        # Step 3 & 4: Load or Build\n",
    "        if vectorstores_exist and not force_rebuild:\n",
    "            print(\"\\n[2/7] Loading existing vectorstores...\")\n",
    "            self._load_vectorstores()\n",
    "        else:\n",
    "            if force_rebuild:\n",
    "                print(\"\\n[2/7] force_rebuild=True â†’ Building vectorstores from scratch...\")\n",
    "            else:\n",
    "                print(\"\\n[2/7] Vectorstores not found â†’ Building from CSVs...\")\n",
    "            self._build_vectorstores()\n",
    "        \n",
    "        # Step 5: Create SmartRetriever\n",
    "        print(\"\\n[3/7] Creating Smart Retriever...\")\n",
    "        self.smart_retriever = SmartRetriever(\n",
    "            vectorstore_recipes=self.vectorstore_recipes,\n",
    "            vectorstore_nutrition=self.vectorstore_nutrition,\n",
    "            k=self.k\n",
    "        )\n",
    "        print(f\"âœ… Smart Retriever ready (k={self.k})\")\n",
    "        \n",
    "        # Step 6: Initialize LLM\n",
    "        print(\"\\n[4/7] Initializing Ollama LLM...\")\n",
    "        self.llm = OllamaLLM(\n",
    "            model=self.model_name,\n",
    "            temperature=self.temperature,\n",
    "            base_url=self.ollama_base_url\n",
    "        )\n",
    "        \n",
    "        # Test LLM connection\n",
    "        try:\n",
    "            test_response = self.llm.invoke(\"Say 'OK' if you can read this.\")\n",
    "            print(f\"âœ… LLM connected: {self.model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LLM Connection Error: {e}\")\n",
    "            raise\n",
    "        \n",
    "        # Step 7: Build RAG chain\n",
    "        print(\"\\n[5/7] Building RAG chain...\")\n",
    "        self._build_chain()\n",
    "        print(\"âœ… RAG chain ready\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âœ… INITIALIZATION COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ğŸ“Š System ready with:\")\n",
    "        print(f\"   - Recipes & Meals: {self.vectorstore_recipes.index.ntotal} vectors\")\n",
    "        print(f\"   - Nutrition Facts: {self.vectorstore_nutrition.index.ntotal} vectors\")\n",
    "        print(f\"   - Model: {self.model_name} (temp={self.temperature})\")\n",
    "        print(f\"   - Retrieval: k={self.k}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # Private Methods: Vectorstore Management\n",
    "    # ========================================\n",
    "    \n",
    "    def _load_vectorstores(self) -> None:\n",
    "        \"\"\"Load existing vectorstores from disk.\"\"\"\n",
    "        recipes_db_path = self.vectorstore_path / \"recipes_and_meals_db\"\n",
    "        nutrition_db_path = self.vectorstore_path / \"nutrition_facts_db\"\n",
    "        \n",
    "        print(f\"   Loading RECIPES_AND_MEALS from {recipes_db_path}...\")\n",
    "        self.vectorstore_recipes = FAISS.load_local(\n",
    "            folder_path=str(recipes_db_path),\n",
    "            embeddings=self.embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        \n",
    "        print(f\"   Loading NUTRITION_FACTS from {nutrition_db_path}...\")\n",
    "        self.vectorstore_nutrition = FAISS.load_local(\n",
    "            folder_path=str(nutrition_db_path),\n",
    "            embeddings=self.embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Vectorstores loaded:\")\n",
    "        print(f\"   - Recipes: {self.vectorstore_recipes.index.ntotal} vectors\")\n",
    "        print(f\"   - Nutrition: {self.vectorstore_nutrition.index.ntotal} vectors\")\n",
    "    \n",
    "    def _build_vectorstores(self) -> None:\n",
    "        \"\"\"Build vectorstores from CSV files.\"\"\"\n",
    "        print(\"   Loading CSV files...\")\n",
    "        \n",
    "        # Load all documents\n",
    "        recipes1 = self._load_recipes_csv(str(self.data_folder / \"cleaned_recipes.csv\"))\n",
    "        recipes2 = self._load_recipes_data_sample_csv(str(self.data_folder / \"cleaned_recipes_data_sample.csv\"))\n",
    "        meals = self._load_healthy_meals_csv(str(self.data_folder / \"cleaned_healthy_meals.csv\"))\n",
    "        nutrition = self._load_nutrition_csv(str(self.data_folder / \"cleaned_nutrition.csv\"))\n",
    "        \n",
    "        # Combine\n",
    "        recipes_and_meals_docs = recipes1 + recipes2 + meals\n",
    "        nutrition_facts_docs = nutrition\n",
    "        \n",
    "        print(f\"   Loaded documents:\")\n",
    "        print(f\"   - Recipes & Meals: {len(recipes_and_meals_docs)}\")\n",
    "        print(f\"   - Nutrition Facts: {len(nutrition_facts_docs)}\")\n",
    "        \n",
    "        # Create vectorstores\n",
    "        print(\"   Creating FAISS vectorstores...\")\n",
    "        self.vectorstore_recipes = FAISS.from_documents(\n",
    "            documents=recipes_and_meals_docs,\n",
    "            embedding=self.embeddings,\n",
    "            distance_strategy=DistanceStrategy.COSINE\n",
    "        )\n",
    "        \n",
    "        self.vectorstore_nutrition = FAISS.from_documents(\n",
    "            documents=nutrition_facts_docs,\n",
    "            embedding=self.embeddings,\n",
    "            distance_strategy=DistanceStrategy.COSINE\n",
    "        )\n",
    "        \n",
    "        # Save to disk\n",
    "        print(\"   Saving vectorstores to disk...\")\n",
    "        self.vectorstore_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        recipes_db_path = self.vectorstore_path / \"recipes_and_meals_db\"\n",
    "        nutrition_db_path = self.vectorstore_path / \"nutrition_facts_db\"\n",
    "        \n",
    "        self.vectorstore_recipes.save_local(str(recipes_db_path))\n",
    "        self.vectorstore_nutrition.save_local(str(nutrition_db_path))\n",
    "        \n",
    "        print(f\"âœ… Vectorstores built and saved:\")\n",
    "        print(f\"   - {recipes_db_path}\")\n",
    "        print(f\"   - {nutrition_db_path}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # Private Methods: Data Loading\n",
    "    # ========================================\n",
    "    \n",
    "    def _load_recipes_csv(self, csv_path: str) -> List[Document]:\n",
    "        \"\"\"Load cleaned_recipes.csv with structured nutrition parsing.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        documents = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row['recipe_name']):\n",
    "                continue\n",
    "            \n",
    "            # Build text\n",
    "            text_parts = [\n",
    "                f\"Recipe: {row['recipe_name']}\",\n",
    "                f\"\\nCuisine: {row.get('cuisine_path', 'Not specified')}\",\n",
    "                f\"\\nIngredients:\\n{row['ingredients']}\",\n",
    "                f\"\\nDirections:\\n{row['directions']}\"\n",
    "            ]\n",
    "            \n",
    "            if pd.notna(row.get('prep_time')):\n",
    "                text_parts.append(f\"\\nPrep Time: {row['prep_time']}\")\n",
    "            if pd.notna(row.get('cook_time')):\n",
    "                text_parts.append(f\"\\nCook Time: {row['cook_time']}\")\n",
    "            if pd.notna(row.get('nutrition')):\n",
    "                text_parts.append(f\"\\nNutrition Facts: {row['nutrition']}\")\n",
    "            \n",
    "            full_text = \"\".join(text_parts)\n",
    "            \n",
    "            # Metadata\n",
    "            metadata = {\n",
    "                'doc_type': 'recipe',\n",
    "                'source_file': 'cleaned_recipes',\n",
    "                'recipe_name': row['recipe_name'],\n",
    "                'servings': row.get('servings', 'Not specified'),\n",
    "            }\n",
    "            \n",
    "            # Parse cuisine\n",
    "            if pd.notna(row.get('cuisine_path')):\n",
    "                cuisine = row['cuisine_path'].split('/')[-1] if '/' in str(row['cuisine_path']) else row['cuisine_path']\n",
    "                metadata['cuisine'] = cuisine\n",
    "            \n",
    "            # Parse timing\n",
    "            if pd.notna(row.get('prep_time')):\n",
    "                prep_str = str(row['prep_time']).lower()\n",
    "                prep_mins = sum([int(s) * (60 if 'hr' in prep_str else 1) \n",
    "                               for s in re.findall(r'\\d+', prep_str)])\n",
    "                metadata['prep_time_min'] = prep_mins\n",
    "            \n",
    "            if pd.notna(row.get('cook_time')):\n",
    "                cook_str = str(row['cook_time']).lower()\n",
    "                cook_mins = sum([int(s) * (60 if 'hr' in cook_str else 1) \n",
    "                               for s in re.findall(r'\\d+', cook_str)])\n",
    "                metadata['cook_time_min'] = cook_mins\n",
    "            \n",
    "            # Extract allergens\n",
    "            ingredients_lower = str(row['ingredients']).lower()\n",
    "            allergens = []\n",
    "            if any(word in ingredients_lower for word in ['milk', 'cheese', 'butter', 'cream', 'yogurt']):\n",
    "                allergens.append('dairy')\n",
    "            if any(word in ingredients_lower for word in ['egg']):\n",
    "                allergens.append('eggs')\n",
    "            if any(word in ingredients_lower for word in ['wheat', 'flour', 'bread']):\n",
    "                allergens.append('gluten')\n",
    "            if any(word in ingredients_lower for word in ['nuts', 'almond', 'peanut', 'walnut']):\n",
    "                allergens.append('nuts')\n",
    "            metadata['allergens'] = allergens\n",
    "            \n",
    "            # Diet tags\n",
    "            diet_tags = []\n",
    "            if 'vegetarian' in ingredients_lower or 'veggie' in ingredients_lower:\n",
    "                diet_tags.append('vegetarian')\n",
    "            if 'vegan' in ingredients_lower:\n",
    "                diet_tags.append('vegan')\n",
    "            if not any(meat in ingredients_lower for meat in ['chicken', 'beef', 'pork', 'fish', 'meat']):\n",
    "                diet_tags.append('vegetarian')\n",
    "            metadata['diet_tags'] = diet_tags\n",
    "            \n",
    "            documents.append(Document(page_content=full_text, metadata=metadata))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _load_recipes_data_sample_csv(self, csv_path: str) -> List[Document]:\n",
    "        \"\"\"Load cleaned_recipes_data_sample.csv with NER parsing.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        documents = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row['title']):\n",
    "                continue\n",
    "            \n",
    "            # Parse ingredients\n",
    "            try:\n",
    "                ingredients_list = ast.literal_eval(row['ingredients'])\n",
    "                ingredients_text = \"\\n\".join([f\"- {ing}\" for ing in ingredients_list])\n",
    "            except:\n",
    "                ingredients_text = row['ingredients']\n",
    "            \n",
    "            # Parse directions\n",
    "            try:\n",
    "                directions_list = ast.literal_eval(row['directions'])\n",
    "                directions_text = \"\\n\".join([f\"{i+1}. {step}\" for i, step in enumerate(directions_list)])\n",
    "            except:\n",
    "                directions_text = row['directions']\n",
    "            \n",
    "            # Parse NER\n",
    "            try:\n",
    "                ner_list = ast.literal_eval(row['NER'])\n",
    "                ner_text = \", \".join(ner_list)\n",
    "            except:\n",
    "                ner_list = []\n",
    "                ner_text = \"\"\n",
    "            \n",
    "            # Build text\n",
    "            text_parts = [\n",
    "                f\"Recipe: {row['title']}\",\n",
    "                f\"\\nIngredients:\\n{ingredients_text}\",\n",
    "                f\"\\nDirections:\\n{directions_text}\",\n",
    "                f\"\\nKey Ingredients: {ner_text}\"\n",
    "            ]\n",
    "            \n",
    "            full_text = \"\".join(text_parts)\n",
    "            \n",
    "            # Metadata\n",
    "            metadata = {\n",
    "                'doc_type': 'recipe',\n",
    "                'source_file': 'cleaned_recipes_data_sample',\n",
    "                'recipe_name': row['title'],\n",
    "                'ingredient_list': ner_list if ner_list else None\n",
    "            }\n",
    "            \n",
    "            # Extract allergens\n",
    "            ingredients_lower = str(row['ingredients']).lower()\n",
    "            allergens = []\n",
    "            if any(word in ingredients_lower for word in ['milk', 'cheese', 'butter', 'cream', 'yogurt']):\n",
    "                allergens.append('dairy')\n",
    "            if any(word in ingredients_lower for word in ['egg']):\n",
    "                allergens.append('eggs')\n",
    "            if any(word in ingredients_lower for word in ['wheat', 'flour', 'bread']):\n",
    "                allergens.append('gluten')\n",
    "            if any(word in ingredients_lower for word in ['nuts', 'almond', 'peanut', 'walnut']):\n",
    "                allergens.append('nuts')\n",
    "            metadata['allergens'] = allergens\n",
    "            \n",
    "            # Diet tags\n",
    "            diet_tags = []\n",
    "            if not any(meat in ingredients_lower for meat in ['chicken', 'beef', 'pork', 'fish', 'meat', 'lamb']):\n",
    "                diet_tags.append('vegetarian')\n",
    "            metadata['diet_tags'] = diet_tags\n",
    "            \n",
    "            documents.append(Document(page_content=full_text, metadata=metadata))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _load_healthy_meals_csv(self, csv_path: str) -> List[Document]:\n",
    "        \"\"\"Load cleaned_healthy_meals.csv with numeric nutrition metadata.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        documents = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row['meal_name']):\n",
    "                continue\n",
    "            \n",
    "            # Build text\n",
    "            text = f\"\"\"Meal: {row['meal_name']} ({row['cuisine']} {row['meal_type']})\n",
    "Diet Type: {row['diet_type']}\n",
    "\n",
    "Nutrition per {row['serving_size_g']}g serving:\n",
    "- Calories: {row['calories']} kcal\n",
    "- Protein: {row['protein_g']}g | Carbs: {row['carbs_g']}g | Fat: {row['fat_g']}g\n",
    "- Fiber: {row['fiber_g']}g | Sugar: {row['sugar_g']}g\n",
    "- Sodium: {row['sodium_mg']}mg | Cholesterol: {row['cholesterol_mg']}mg\n",
    "\n",
    "Preparation: {row['cooking_method']} (Prep: {row['prep_time_min']}min, Cook: {row['cook_time_min']}min)\n",
    "\"\"\"\n",
    "            \n",
    "            # Metadata\n",
    "            metadata = {\n",
    "                'doc_type': 'meal',\n",
    "                'source_file': 'cleaned_healthy_meals',\n",
    "                'recipe_name': row['meal_name'],\n",
    "                'cuisine': row['cuisine'],\n",
    "                'meal_type': row['meal_type'],\n",
    "                'diet_type': row['diet_type'],\n",
    "                'calories': int(row['calories']),\n",
    "                'protein_g': float(row['protein_g']),\n",
    "                'carbs_g': float(row['carbs_g']),\n",
    "                'fat_g': float(row['fat_g']),\n",
    "                'fiber_g': float(row['fiber_g']),\n",
    "                'sugar_g': float(row['sugar_g']),\n",
    "                'sodium_mg': int(row['sodium_mg']),\n",
    "                'cholesterol_mg': int(row['cholesterol_mg']),\n",
    "                'serving_size_g': int(row['serving_size_g']),\n",
    "                'cooking_method': row['cooking_method'],\n",
    "                'prep_time_min': int(row['prep_time_min']),\n",
    "                'cook_time_min': int(row['cook_time_min'])\n",
    "            }\n",
    "            \n",
    "            # Diet tags\n",
    "            diet_tags = [row['diet_type'].lower()]\n",
    "            if row['diet_type'].lower() in ['vegan', 'vegetarian']:\n",
    "                diet_tags.append('vegetarian')\n",
    "            metadata['diet_tags'] = diet_tags\n",
    "            \n",
    "            # Allergens\n",
    "            allergens = []\n",
    "            meal_lower = row['meal_name'].lower()\n",
    "            if any(word in meal_lower for word in ['cheese', 'yogurt', 'milk']):\n",
    "                allergens.append('dairy')\n",
    "            metadata['allergens'] = allergens\n",
    "            \n",
    "            documents.append(Document(page_content=text, metadata=metadata))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _load_nutrition_csv(self, csv_path: str) -> List[Document]:\n",
    "        \"\"\"Load cleaned_nutrition.csv - detailed ingredient nutrition database.\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "        documents = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.isna(row['name']):\n",
    "                continue\n",
    "            \n",
    "            # Build text\n",
    "            text = f\"\"\"Ingredient: {row['name']} (per {row['serving_size']})\n",
    "\n",
    "Macronutrients:\n",
    "- Calories: {row['calories']} kcal\n",
    "- Protein: {row['protein']}\n",
    "- Carbohydrates: {row['carbohydrate']}\n",
    "- Total Fat: {row['total_fat']}\n",
    "- Fiber: {row['fiber']}\n",
    "- Sugars: {row['sugars']}\n",
    "\n",
    "Key Vitamins:\n",
    "- Vitamin A: {row['vitamin_a']}\n",
    "- Vitamin C: {row['vitamin_c']}\n",
    "- Vitamin D: {row['vitamin_d']}\n",
    "- Vitamin B12: {row['vitamin_b12']}\n",
    "- Folate: {row['folate']}\n",
    "\n",
    "Key Minerals:\n",
    "- Calcium: {row['calcium']}\n",
    "- Iron: {row['irom']}\n",
    "- Magnesium: {row['magnesium']}\n",
    "- Sodium: {row['sodium']}\n",
    "- Potassium: {row['potassium']}\n",
    "\n",
    "Cholesterol: {row['cholesterol']} | Saturated Fat: {row['saturated_fat']}\n",
    "\"\"\"\n",
    "            \n",
    "            # Metadata\n",
    "            metadata = {\n",
    "                'doc_type': 'nutrition_fact',\n",
    "                'source_file': 'cleaned_nutrition',\n",
    "                'food_name': row['name'],\n",
    "                'serving_size': row['serving_size']\n",
    "            }\n",
    "            \n",
    "            # Extract numeric values\n",
    "            def parse_numeric(val):\n",
    "                if pd.isna(val):\n",
    "                    return None\n",
    "                try:\n",
    "                    return float(re.sub(r'[^\\d.]', '', str(val)))\n",
    "                except:\n",
    "                    return None\n",
    "            \n",
    "            metadata['calories'] = parse_numeric(row['calories'])\n",
    "            metadata['protein_g'] = parse_numeric(row['protein'])\n",
    "            metadata['carbs_g'] = parse_numeric(row['carbohydrate'])\n",
    "            metadata['fat_g'] = parse_numeric(row['total_fat'])\n",
    "            metadata['fiber_g'] = parse_numeric(row['fiber'])\n",
    "            metadata['sugar_g'] = parse_numeric(row['sugars'])\n",
    "            \n",
    "            # Allergens\n",
    "            food_lower = row['name'].lower()\n",
    "            allergens = []\n",
    "            if any(word in food_lower for word in ['milk', 'cheese', 'yogurt', 'cream', 'butter']):\n",
    "                allergens.append('dairy')\n",
    "            if any(word in food_lower for word in ['egg']):\n",
    "                allergens.append('eggs')\n",
    "            if any(word in food_lower for word in ['wheat', 'flour', 'bread']):\n",
    "                allergens.append('gluten')\n",
    "            if any(word in food_lower for word in ['nuts', 'almond', 'peanut', 'walnut', 'pecan']):\n",
    "                allergens.append('nuts')\n",
    "            metadata['allergens'] = allergens\n",
    "            \n",
    "            documents.append(Document(page_content=text, metadata=metadata))\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    # ========================================\n",
    "    # Private Methods: RAG Chain\n",
    "    # ========================================\n",
    "    \n",
    "    def _build_chain(self) -> None:\n",
    "        \"\"\"Build RAG chain with system prompt.\"\"\"\n",
    "        prompt_template = ChatPromptTemplate.from_template(self.SYSTEM_PROMPT)\n",
    "        \n",
    "        stuff_documents_chain = create_stuff_documents_chain(\n",
    "            llm=self.llm,\n",
    "            prompt=prompt_template\n",
    "        )\n",
    "        \n",
    "        self.rag_chain = create_retrieval_chain(\n",
    "            retriever=self.smart_retriever,\n",
    "            combine_docs_chain=stuff_documents_chain\n",
    "        )\n",
    "    \n",
    "    # ========================================\n",
    "    # Public Methods\n",
    "    # ========================================\n",
    "    \n",
    "    def query(self, user_input: str) -> str:\n",
    "        \"\"\"\n",
    "        Main interface - get recipe recommendations.\n",
    "        \n",
    "        Args:\n",
    "            user_input: User's query (e.g., \"vegetarian high-protein meal under 500 calories\")\n",
    "        \n",
    "        Returns:\n",
    "            AI-generated recipe recommendations\n",
    "        \"\"\"\n",
    "        if not self.rag_chain:\n",
    "            return \"âŒ System not initialized. Call initialize() first.\"\n",
    "        \n",
    "        response = self.rag_chain.invoke({\"input\": user_input})\n",
    "        return response.get(\"answer\", \"No response generated.\")\n",
    "    \n",
    "    def get_retrieved_docs(self, query: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Debug method - see which documents are retrieved for a query.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query\n",
    "        \n",
    "        Returns:\n",
    "            List of retrieved Document objects\n",
    "        \"\"\"\n",
    "        if not self.smart_retriever:\n",
    "            print(\"âŒ System not initialized. Call initialize() first.\")\n",
    "            return []\n",
    "        \n",
    "        return self.smart_retriever.invoke(query)\n",
    "    \n",
    "    def reload_vectorstores(self) -> None:\n",
    "        \"\"\"\n",
    "        Reload vectorstores from disk (useful after manual updates).\n",
    "        \"\"\"\n",
    "        print(\"ğŸ”„ Reloading vectorstores...\")\n",
    "        self._load_vectorstores()\n",
    "        \n",
    "        # Recreate SmartRetriever\n",
    "        self.smart_retriever = SmartRetriever(\n",
    "            vectorstore_recipes=self.vectorstore_recipes,\n",
    "            vectorstore_nutrition=self.vectorstore_nutrition,\n",
    "            k=self.k\n",
    "        )\n",
    "        \n",
    "        # Rebuild chain\n",
    "        self._build_chain()\n",
    "        print(\"âœ… Vectorstores reloaded and chain rebuilt\")\n",
    "    \n",
    "    def update_system_prompt(self, new_prompt: str) -> None:\n",
    "        \"\"\"\n",
    "        Update the system prompt and rebuild the chain.\n",
    "        \n",
    "        Args:\n",
    "            new_prompt: New system prompt (must contain {input} and {context} placeholders)\n",
    "        \"\"\"\n",
    "        if \"{input}\" not in new_prompt or \"{context}\" not in new_prompt:\n",
    "            print(\"âŒ Error: Prompt must contain {input} and {context} placeholders\")\n",
    "            return\n",
    "        \n",
    "        print(\"ğŸ”„ Updating system prompt...\")\n",
    "        self.SYSTEM_PROMPT = new_prompt\n",
    "        self._build_chain()\n",
    "        print(\"âœ… System prompt updated and chain rebuilt\")\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get system statistics and configuration.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with system info\n",
    "        \"\"\"\n",
    "        if not self.vectorstore_recipes or not self.vectorstore_nutrition:\n",
    "            return {\"status\": \"not_initialized\"}\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"initialized\",\n",
    "            \"model\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"k\": self.k,\n",
    "            \"vectorstores\": {\n",
    "                \"recipes_and_meals\": {\n",
    "                    \"vectors\": self.vectorstore_recipes.index.ntotal,\n",
    "                    \"path\": str(self.vectorstore_path / \"recipes_and_meals_db\")\n",
    "                },\n",
    "                \"nutrition_facts\": {\n",
    "                    \"vectors\": self.vectorstore_nutrition.index.ntotal,\n",
    "                    \"path\": str(self.vectorstore_path / \"nutrition_facts_db\")\n",
    "                }\n",
    "            },\n",
    "            \"data_folder\": str(self.data_folder),\n",
    "            \"ollama_url\": self.ollama_base_url\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"âœ… RecipesNutritionRAG class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29c0dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RecipesNutritionRAG created (NOT initialized yet)\n",
      "   Data folder: ..\\data\n",
      "   Vectorstore path: ..\\vector_databases\n",
      "   Model: llama3.2\n",
      "   Temperature: 0.5\n",
      "   k: 10\n",
      "\n",
      "============================================================\n",
      "ğŸš€ INITIALIZING RecipesNutritionRAG\n",
      "============================================================\n",
      "\n",
      "[1/7] Initializing embedding model...\n",
      "âœ… Embeddings ready\n",
      "\n",
      "[2/7] Loading existing vectorstores...\n",
      "   Loading RECIPES_AND_MEALS from ..\\vector_databases\\recipes_and_meals_db...\n",
      "   Loading NUTRITION_FACTS from ..\\vector_databases\\nutrition_facts_db...\n",
      "âœ… Vectorstores loaded:\n",
      "   - Recipes: 5090 vectors\n",
      "   - Nutrition: 8789 vectors\n",
      "\n",
      "[3/7] Creating Smart Retriever...\n",
      "âœ… Smart Retriever ready (k=10)\n",
      "\n",
      "[4/7] Initializing Ollama LLM...\n",
      "âœ… LLM connected: llama3.2\n",
      "\n",
      "[5/7] Building RAG chain...\n",
      "âœ… RAG chain ready\n",
      "\n",
      "============================================================\n",
      "âœ… INITIALIZATION COMPLETE!\n",
      "============================================================\n",
      "ğŸ“Š System ready with:\n",
      "   - Recipes & Meals: 5090 vectors\n",
      "   - Nutrition Facts: 8789 vectors\n",
      "   - Model: llama3.2 (temp=0.5)\n",
      "   - Retrieval: k=10\n",
      "\n",
      "ğŸ“Š System Statistics:\n",
      "{\n",
      "  \"status\": \"initialized\",\n",
      "  \"model\": \"llama3.2\",\n",
      "  \"temperature\": 0.5,\n",
      "  \"k\": 10,\n",
      "  \"vectorstores\": {\n",
      "    \"recipes_and_meals\": {\n",
      "      \"vectors\": 5090,\n",
      "      \"path\": \"..\\\\vector_databases\\\\recipes_and_meals_db\"\n",
      "    },\n",
      "    \"nutrition_facts\": {\n",
      "      \"vectors\": 8789,\n",
      "      \"path\": \"..\\\\vector_databases\\\\nutrition_facts_db\"\n",
      "    }\n",
      "  },\n",
      "  \"data_folder\": \"..\\\\data\",\n",
      "  \"ollama_url\": \"http://localhost:11434/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Test RecipesNutritionRAG Class\n",
    "# ========================================\n",
    "\n",
    "# Import json for stats display\n",
    "import json\n",
    "\n",
    "# Initialize the class\n",
    "rag_system = RecipesNutritionRAG(\n",
    "    data_folder=\"../data/\",\n",
    "    vectorstore_path=\"../vector_databases/\",\n",
    "    model_name=\"llama3.2\",\n",
    "    temperature=0.5,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# Setup (loads existing vectorstores OR builds if not exist)\n",
    "rag_system.initialize(force_rebuild=False)\n",
    "\n",
    "# Get stats\n",
    "stats = rag_system.get_stats()\n",
    "print(\"\\nğŸ“Š System Statistics:\")\n",
    "print(json.dumps(stats, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d36b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing RAG System Query\n",
      "\n",
      "Query: I need a vegetarian high-protein meal under 500 calories. What do you recommend?\n",
      "\n",
      "============================================================\n",
      "ğŸ” Query type detected: BOTH\n",
      "   â†’ Searched BOTH collections\n",
      "### Recipe Name: High-Protein Vegetarian Soup\n",
      "\n",
      "**2. Why This Recipe:**\n",
      "- Meets calorie/protein requirements\n",
      "- Dietary compliance (vegetarian)\n",
      "- Medical alignment (suitable for most individuals)\n",
      "\n",
      "**3. Adaptations Made:** \n",
      "- Original â†’ Modified â†’ Reason: None needed; adapted from 'Soup (Italian Snack)' to meet protein and calorie requirements.\n",
      "\n",
      "**4. Nutritional Information (per serving):**\n",
      "- Calories: 296 kcal\n",
      "- Protein: 74.8g\n",
      "- Carbohydrates: 27.2g\n",
      "- Fat: 24.0g\n",
      "- Fiber: 25.7g\n",
      "- Sodium: 2467mg\n",
      "\n",
      "**5. Ingredients:**\n",
      "- 200g Vegetarian meatballs or patties (- XXXg)\n",
      "- 400ml Vegetable broth (approximately, adjusted for serving)\n",
      "- 150g Spinach\n",
      "- 100g Tomatoes\n",
      "- 15ml Olive oil\n",
      "- 5g Salt\n",
      "\n",
      "**6. Cooking Instructions:**\n",
      "1. Preheat oven to 180Â°C\n",
      "2. Heat 15ml olive oil in a large pot over medium heat\n",
      "3. Add 200g meatballs or patties and cook for 5-7 minutes until browned\n",
      "4. Add 400ml broth, 100g tomatoes, and 150g spinach, bring to simmer\n",
      "5. Season with 5g salt, serve hot\n",
      "\n",
      "**7. Time Information:**\n",
      "- Preparation Time: 15 minutes\n",
      "- Cooking Time: 30 minutes  \n",
      "- Total Time: 45 minutes\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Test Query Method\n",
    "# ========================================\n",
    "\n",
    "# Test query\n",
    "test_query = \"I need a vegetarian high-protein meal under 500 calories. What do you recommend?\"\n",
    "\n",
    "print(\"ğŸ§ª Testing RAG System Query\\n\")\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response = rag_system.query(test_query)\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67872b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing get_retrieved_docs() method\n",
      "\n",
      "============================================================\n",
      "ğŸ” Query type detected: BOTH\n",
      "   â†’ Searched BOTH collections\n",
      "\n",
      "ğŸ“Š Retrieved 10 documents:\n",
      "\n",
      "\n",
      "--- Document 1 ---\n",
      "Type: meal\n",
      "Name: Try Soup\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 196 kcal\n",
      "Protein: 74.8g\n",
      "Content preview: Meal: Try Soup (Italian Snack)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 325g serving:\n",
      "- Calories: 196 kcal\n",
      "- Protein: 74.8g | Carbs: 27.2g | Fat: 24.0g\n",
      "- ...\n",
      "\n",
      "--- Document 2 ---\n",
      "Type: meal\n",
      "Name: Above Stew\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 416 kcal\n",
      "Protein: 22.5g\n",
      "Content preview: Meal: Above Stew (American Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 186g serving:\n",
      "- Calories: 416 kcal\n",
      "- Protein: 22.5g | Carbs: 138.9g | Fat: 3.0g...\n",
      "\n",
      "--- Document 3 ---\n",
      "Type: meal\n",
      "Name: Once Rice\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 244 kcal\n",
      "Protein: 13.8g\n",
      "Content preview: Meal: Once Rice (American Breakfast)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 265g serving:\n",
      "- Calories: 244 kcal\n",
      "- Protein: 13.8g | Carbs: 36.9g | Fat: 15...\n",
      "\n",
      "--- Document 4 ---\n",
      "Type: meal\n",
      "Name: Once Wrap\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 434 kcal\n",
      "Protein: 51.8g\n",
      "Content preview: Meal: Once Wrap (American Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 361g serving:\n",
      "- Calories: 434 kcal\n",
      "- Protein: 51.8g | Carbs: 7.2g | Fat: 50.8g\n",
      "-...\n",
      "\n",
      "--- Document 5 ---\n",
      "Type: meal\n",
      "Name: Eat Rice\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 342 kcal\n",
      "Protein: 72.0g\n",
      "Content preview: Meal: Eat Rice (American Dinner)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 334g serving:\n",
      "- Calories: 342 kcal\n",
      "- Protein: 72.0g | Carbs: 52.2g | Fat: 27.3g\n",
      "...\n",
      "\n",
      "--- Document 6 ---\n",
      "Type: meal\n",
      "Name: Base Rice\n",
      "Source: cleaned_healthy_meals\n",
      "Calories: 356 kcal\n",
      "Protein: 18.8g\n",
      "Content preview: Meal: Base Rice (Chinese Lunch)\n",
      "Diet Type: Vegetarian\n",
      "\n",
      "Nutrition per 126g serving:\n",
      "- Calories: 356 kcal\n",
      "- Protein: 18.8g | Carbs: 48.2g | Fat: 49.3g\n",
      "-...\n",
      "\n",
      "--- Document 7 ---\n",
      "Type: nutrition_fact\n",
      "Name: Vegetarian meatloaf or patties\n",
      "Source: cleaned_nutrition\n",
      "Calories: 197.0 kcal\n",
      "Protein: 21.0g\n",
      "Content preview: Ingredient: Vegetarian meatloaf or patties (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 197 kcal\n",
      "- Protein: 21.00 g\n",
      "- Carbohydrates: 8.00 g\n",
      "- Total Fat: 9...\n",
      "\n",
      "--- Document 8 ---\n",
      "Type: nutrition_fact\n",
      "Name: MORNINGSTAR FARMS Meal Starters Veggie Meatballs, unprepared, frozen\n",
      "Source: cleaned_nutrition\n",
      "Calories: 158.0 kcal\n",
      "Protein: 17.7g\n",
      "Content preview: Ingredient: MORNINGSTAR FARMS Meal Starters Veggie Meatballs, unprepared, frozen (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 158 kcal\n",
      "- Protein: 17.70 g\n",
      "...\n",
      "\n",
      "--- Document 9 ---\n",
      "Type: nutrition_fact\n",
      "Name: WORTHINGTON Vegetarian Burger, unprepared, canned\n",
      "Source: cleaned_nutrition\n",
      "Calories: 124.0 kcal\n",
      "Protein: 18.6g\n",
      "Content preview: Ingredient: WORTHINGTON Vegetarian Burger, unprepared, canned (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 124 kcal\n",
      "- Protein: 18.60 g\n",
      "- Carbohydrates: 6....\n",
      "\n",
      "--- Document 10 ---\n",
      "Type: nutrition_fact\n",
      "Name: Vegetarian fillets\n",
      "Source: cleaned_nutrition\n",
      "Calories: 290.0 kcal\n",
      "Protein: 23.0g\n",
      "Content preview: Ingredient: Vegetarian fillets (per 100 g)\n",
      "\n",
      "Macronutrients:\n",
      "- Calories: 290 kcal\n",
      "- Protein: 23.00 g\n",
      "- Carbohydrates: 9.00 g\n",
      "- Total Fat: 18g\n",
      "- Fiber: ...\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Test Debug Methods\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸ” Testing get_retrieved_docs() method\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get retrieved documents for inspection\n",
    "test_query_debug = \"vegetarian high-protein meal under 500 calories\"\n",
    "docs = rag_system.get_retrieved_docs(test_query_debug)\n",
    "\n",
    "print(f\"\\nğŸ“Š Retrieved {len(docs)} documents:\\n\")\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(f\"Type: {doc.metadata.get('doc_type')}\")\n",
    "    print(f\"Name: {doc.metadata.get('recipe_name', doc.metadata.get('food_name'))}\")\n",
    "    print(f\"Source: {doc.metadata.get('source_file')}\")\n",
    "    \n",
    "    # Show nutrition if available\n",
    "    if 'calories' in doc.metadata:\n",
    "        print(f\"Calories: {doc.metadata['calories']} kcal\")\n",
    "    if 'protein_g' in doc.metadata:\n",
    "        print(f\"Protein: {doc.metadata['protein_g']}g\")\n",
    "    \n",
    "    # Show preview\n",
    "    print(f\"Content preview: {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06bf40e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Production file created: ../src/recipes_nutrition_rag.py\n",
      "ğŸ“¦ File size: 13.54 KB\n",
      "\n",
      "ğŸ¯ Next steps:\n",
      "1. Test the exported file:\n",
      "   from src.recipes_nutrition_rag import RecipesNutritionRAG\n",
      "2. Use in your Streamlit app\n",
      "3. Deploy to production\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# STEP 7: Export RecipesNutritionRAG to Production File\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Define target file path\n",
    "output_file = \"../src/recipes_nutrition_rag.py\"\n",
    "\n",
    "# Ensure src directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Complete production code\n",
    "production_code = '''\"\"\"\n",
    "RecipesNutritionRAG - Production-Ready RAG System for Recipe Recommendations\n",
    "\n",
    "This module provides a complete RAG (Retrieval-Augmented Generation) system for\n",
    "personalized recipe recommendations based on nutritional requirements.\n",
    "\n",
    "Features:\n",
    "- Dual vectorstore system (recipes + nutrition facts)\n",
    "- Smart query routing (recipes/nutrition/both)\n",
    "- Intelligent retrieval with configurable k\n",
    "- Medical-grade system prompt with complete recipe structure\n",
    "- Auto-detects and loads/builds vectorstores\n",
    "\n",
    "Author: GitHub Copilot Assistant\n",
    "Created: February 9, 2026\n",
    "\"\"\"\n",
    "\n",
    "# ========================================\n",
    "# IMPORTS\n",
    "# ========================================\n",
    "\n",
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain Components\n",
    "from langchain.schema import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "# Python Standard Library\n",
    "import ast\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# HELPER FUNCTIONS\n",
    "# ========================================\n",
    "\n",
    "def determine_query_type(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Intelligently route queries to the right collection.\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "    \n",
    "    Returns:\n",
    "        'recipes', 'nutrition', or 'both'\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    recipe_keywords = [\n",
    "        'recipe', 'meal', 'cook', 'prepare', 'make', 'dish', \n",
    "        'breakfast', 'lunch', 'dinner', 'snack',\n",
    "        'vegetarian', 'vegan', 'keto', 'paleo',\n",
    "        'cuisine', 'italian', 'chinese', 'indian'\n",
    "    ]\n",
    "    \n",
    "    nutrition_keywords = [\n",
    "        'nutrition', 'nutrient', 'vitamin', 'mineral', \n",
    "        'calorie', 'protein', 'carb', 'fat', 'fiber',\n",
    "        'healthy', 'good source', 'rich in',\n",
    "        'ingredient', 'food'\n",
    "    ]\n",
    "    \n",
    "    recipe_match = any(keyword in query_lower for keyword in recipe_keywords)\n",
    "    nutrition_match = any(keyword in query_lower for keyword in nutrition_keywords)\n",
    "    \n",
    "    if recipe_match and not nutrition_match:\n",
    "        return 'recipes'\n",
    "    elif nutrition_match and not recipe_match:\n",
    "        return 'nutrition'\n",
    "    else:\n",
    "        return 'both'\n",
    "\n",
    "\n",
    "def smart_retrieve(query: str, vectorstore_recipes, vectorstore_nutrition, k: int = 10) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Smart retrieval across collections based on query type.\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "        vectorstore_recipes: FAISS vectorstore for recipes\n",
    "        vectorstore_nutrition: FAISS vectorstore for nutrition facts\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        List of retrieved Document objects\n",
    "    \"\"\"\n",
    "    query_type = determine_query_type(query)\n",
    "    \n",
    "    print(f\"ğŸ” Query type detected: {query_type.upper()}\")\n",
    "    \n",
    "    if query_type == 'recipes':\n",
    "        results = vectorstore_recipes.similarity_search(query, k=k)\n",
    "        print(f\"   â†’ Searched RECIPES_AND_MEALS collection\")\n",
    "    elif query_type == 'nutrition':\n",
    "        results = vectorstore_nutrition.similarity_search(query, k=k)\n",
    "        print(f\"   â†’ Searched NUTRITION_FACTS collection\")\n",
    "    else:\n",
    "        results_recipes = vectorstore_recipes.similarity_search(query, k=k//2 + 1)\n",
    "        results_nutrition = vectorstore_nutrition.similarity_search(query, k=k//2 + 1)\n",
    "        results = results_recipes + results_nutrition\n",
    "        print(f\"   â†’ Searched BOTH collections\")\n",
    "    \n",
    "    return results[:k]\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# SMART RETRIEVER CLASS\n",
    "# ========================================\n",
    "\n",
    "class SmartRetriever(Runnable):\n",
    "    \"\"\"\n",
    "    Intelligent retriever implementing LangChain's Runnable interface.\n",
    "    \n",
    "    Routes queries to appropriate vector collections based on content analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstore_recipes, vectorstore_nutrition, k=10):\n",
    "        \"\"\"\n",
    "        Initialize SmartRetriever.\n",
    "        \n",
    "        Args:\n",
    "            vectorstore_recipes: FAISS vectorstore for recipes\n",
    "            vectorstore_nutrition: FAISS vectorstore for nutrition facts\n",
    "            k: Number of documents to retrieve\n",
    "        \"\"\"\n",
    "        self.vectorstore_recipes = vectorstore_recipes\n",
    "        self.vectorstore_nutrition = vectorstore_nutrition\n",
    "        self.k = k\n",
    "    \n",
    "    def invoke(self, input: dict | str, config: RunnableConfig = None) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Execute smart retrieval based on query analysis.\n",
    "        \n",
    "        Args:\n",
    "            input: Query string or dict with 'input' key\n",
    "            config: Optional Runnable configuration\n",
    "        \n",
    "        Returns:\n",
    "            List of retrieved Document objects\n",
    "        \"\"\"\n",
    "        if isinstance(input, dict):\n",
    "            query = input.get(\"input\", \"\")\n",
    "        else:\n",
    "            query = input\n",
    "            \n",
    "        return smart_retrieve(\n",
    "            query=query,\n",
    "            vectorstore_recipes=self.vectorstore_recipes,\n",
    "            vectorstore_nutrition=self.vectorstore_nutrition,\n",
    "            k=self.k\n",
    "        )\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# MAIN RAG CLASS\n",
    "# ========================================\n",
    "\n",
    "class RecipesNutritionRAG:\n",
    "    \"\"\"\n",
    "    Production-ready RAG system for personalized recipe recommendations.\n",
    "    \n",
    "    Features:\n",
    "    - Dual vectorstore system (recipes + nutrition facts)\n",
    "    - Smart query routing (recipes/nutrition/both)\n",
    "    - Intelligent retrieval with configurable k\n",
    "    - Medical-grade system prompt with full recipe structure\n",
    "    - Auto-detects and loads/builds vectorstores\n",
    "    \n",
    "    Usage:\n",
    "        rag = RecipesNutritionRAG(\n",
    "            data_folder=\"data/\",\n",
    "            vectorstore_path=\"vector_databases/\",\n",
    "            model_name=\"llama3.2\",\n",
    "            temperature=0.5,\n",
    "            k=10\n",
    "        )\n",
    "        \n",
    "        rag.initialize(force_rebuild=False)\n",
    "        response = rag.query(\"vegetarian high-protein meal under 500 calories\")\n",
    "    \"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"You are NutriGuide, an AI nutrition assistant providing personalized recipe recommendations.\n",
    "\n",
    "## CRITICAL SAFETY DISCLAIMER\n",
    "You are a recommendation system ONLY. Your suggestions do NOT replace professional medical advice from healthcare providers.\n",
    "\n",
    "## STRICT OUTPUT REQUIREMENTS\n",
    "\n",
    "For EVERY recipe recommendation, you MUST include ALL of the following sections in this exact order:\n",
    "\n",
    "### MANDATORY SECTIONS (DO NOT SKIP ANY):\n",
    "\n",
    "**1. Recipe Name** (Adapted if modified)\n",
    "\n",
    "**2. Why This Recipe:**\n",
    "- Meets calorie/protein requirements\n",
    "- Dietary compliance (vegetarian, vegan, etc.)\n",
    "- Medical alignment (if applicable)\n",
    "\n",
    "**3. Adaptations Made:** (if any)\n",
    "- State \"No adaptations needed\" if recipe matches perfectly\n",
    "- OR list: Original â†’ Modified â†’ Reason\n",
    "\n",
    "**4. Nutritional Information (per serving):**\n",
    "- Calories: X kcal\n",
    "- Protein: X g\n",
    "- Carbohydrates: X g  \n",
    "- Fat: X g\n",
    "- Fiber: X g (if relevant)\n",
    "- Sodium: X mg (if relevant)\n",
    "\n",
    "**5. Ingredients (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and list ingredients from the retrieved context.**\n",
    "**If ingredient quantities are missing in context, you MUST:**\n",
    "- Estimate reasonable quantities based on the serving size\n",
    "- Mark estimates with (approximately)\n",
    "- Convert ALL measurements to metric: grams (g), milliliters (ml)\n",
    "- Format: `- XXXg ingredient name` or `- XXml liquid name`\n",
    "\n",
    "**6. Cooking Instructions (CRITICAL - NEVER SKIP):**\n",
    "**ALWAYS extract and provide step-by-step instructions from the retrieved context.**\n",
    "**If instructions are missing, you MUST:**\n",
    "- Create logical cooking steps based on the ingredients\n",
    "- Include temperatures in Celsius (Â°C)\n",
    "- Number each step clearly\n",
    "\n",
    "**7. Time Information:**\n",
    "- Preparation Time: X minutes\n",
    "- Cooking Time: X minutes  \n",
    "- Total Time: X minutes\n",
    "\n",
    "---\n",
    "\n",
    "## HANDLING MISSING DATA\n",
    "\n",
    "**If retrieved context lacks ingredient quantities:**\n",
    "â†’ You MUST estimate based on:\n",
    "- Serving size (e.g., 325g serving = ~300-350g total ingredients)\n",
    "- Standard recipe proportions\n",
    "- Mark as \"(approximately)\" or \"(estimated for 1 serving)\"\n",
    "\n",
    "**If retrieved context lacks cooking instructions:**\n",
    "â†’ You MUST create logical steps based on:\n",
    "- Ingredient types (raw â†’ needs cooking)\n",
    "- Preparation method stated (Baked, Fried, Raw, etc.)\n",
    "- Standard cooking techniques\n",
    "\n",
    "**NEVER say:** \"Cooking instructions not available in database\"  \n",
    "**ALWAYS provide:** Complete, usable recipe instructions\n",
    "\n",
    "---\n",
    "\n",
    "## MEASUREMENT CONVERSIONS (STRICT)\n",
    "\n",
    "**Convert ALL measurements to metric:**\n",
    "- 1 cup â†’ 240 ml\n",
    "- 1 tbsp â†’ 15 ml\n",
    "- 1 tsp â†’ 5 ml\n",
    "- 1 oz â†’ 28 g\n",
    "- 1 lb â†’ 454 g\n",
    "\n",
    "**Temperatures MUST be Celsius:**\n",
    "- 350Â°F â†’ 175Â°C\n",
    "- 400Â°F â†’ 200Â°C\n",
    "\n",
    "---\n",
    "\n",
    "## YOUR TASK NOW:\n",
    "\n",
    "User Query: {input}\n",
    "\n",
    "Retrieved Context: {context}\n",
    "\n",
    "Generate 3 complete recipe recommendations following the MANDATORY SECTIONS structure above.\n",
    "**DO NOT skip Ingredients or Cooking Instructions sections.**\n",
    "**If data is missing, estimate based on serving size and recipe type.**\n",
    "\n",
    "âš ï¸ **Important Reminder**: These are suggestions based on general nutrition principles. Consult healthcare providers before dietary changes.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_folder: str,\n",
    "        vectorstore_path: str,\n",
    "        model_name: str = \"llama3.2\",\n",
    "        temperature: float = 0.5,\n",
    "        k: int = 10,\n",
    "        ollama_base_url: str = \"http://localhost:11434/\"\n",
    "    ):\n",
    "        \"\"\"Initialize RecipesNutritionRAG (call initialize() to load data).\"\"\"\n",
    "        self.data_folder = Path(data_folder)\n",
    "        self.vectorstore_path = Path(vectorstore_path)\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.k = k\n",
    "        self.ollama_base_url = ollama_base_url\n",
    "        \n",
    "        self.embeddings = None\n",
    "        self.vectorstore_recipes = None\n",
    "        self.vectorstore_nutrition = None\n",
    "        self.smart_retriever = None\n",
    "        self.llm = None\n",
    "        self.rag_chain = None\n",
    "        \n",
    "        print(f\"âœ… RecipesNutritionRAG created\")\n",
    "        print(f\"   Model: {self.model_name} | Temperature: {self.temperature} | k: {self.k}\")\n",
    "    \n",
    "    def initialize(self, force_rebuild: bool = False) -> None:\n",
    "        \"\"\"Initialize the RAG system.\"\"\"\n",
    "        print(\"\\\\nğŸš€ Initializing RecipesNutritionRAG...\")\n",
    "        \n",
    "        # Load embeddings\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "            encode_kwargs={\"normalize_embeddings\": True}\n",
    "        )\n",
    "        \n",
    "        # Load vectorstores\n",
    "        recipes_db_path = self.vectorstore_path / \"recipes_and_meals_db\"\n",
    "        nutrition_db_path = self.vectorstore_path / \"nutrition_facts_db\"\n",
    "        \n",
    "        if not force_rebuild and recipes_db_path.exists() and nutrition_db_path.exists():\n",
    "            print(\"ğŸ“‚ Loading existing vectorstores...\")\n",
    "            self.vectorstore_recipes = FAISS.load_local(\n",
    "                folder_path=str(recipes_db_path),\n",
    "                embeddings=self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            self.vectorstore_nutrition = FAISS.load_local(\n",
    "                folder_path=str(nutrition_db_path),\n",
    "                embeddings=self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Vectorstores not found. Build them first using the notebook.\")\n",
    "        \n",
    "        # Create retriever\n",
    "        self.smart_retriever = SmartRetriever(\n",
    "            vectorstore_recipes=self.vectorstore_recipes,\n",
    "            vectorstore_nutrition=self.vectorstore_nutrition,\n",
    "            k=self.k\n",
    "        )\n",
    "        \n",
    "        # Initialize LLM\n",
    "        self.llm = OllamaLLM(\n",
    "            model=self.model_name,\n",
    "            temperature=self.temperature,\n",
    "            base_url=self.ollama_base_url\n",
    "        )\n",
    "        \n",
    "        # Build chain\n",
    "        prompt_template = ChatPromptTemplate.from_template(self.SYSTEM_PROMPT)\n",
    "        stuff_documents_chain = create_stuff_documents_chain(\n",
    "            llm=self.llm,\n",
    "            prompt=prompt_template\n",
    "        )\n",
    "        self.rag_chain = create_retrieval_chain(\n",
    "            retriever=self.smart_retriever,\n",
    "            combine_docs_chain=stuff_documents_chain\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Initialization complete!\")\n",
    "    \n",
    "    def query(self, user_input: str) -> str:\n",
    "        \"\"\"Get recipe recommendations.\"\"\"\n",
    "        if not self.rag_chain:\n",
    "            return \"âŒ System not initialized. Call initialize() first.\"\n",
    "        \n",
    "        response = self.rag_chain.invoke({\"input\": user_input})\n",
    "        return response.get(\"answer\", \"No response generated.\")\n",
    "    \n",
    "    def get_retrieved_docs(self, query: str) -> List[Document]:\n",
    "        \"\"\"Debug method - see retrieved documents.\"\"\"\n",
    "        if not self.smart_retriever:\n",
    "            print(\"âŒ System not initialized.\")\n",
    "            return []\n",
    "        return self.smart_retriever.invoke(query)\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get system statistics.\"\"\"\n",
    "        if not self.vectorstore_recipes or not self.vectorstore_nutrition:\n",
    "            return {\"status\": \"not_initialized\"}\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"initialized\",\n",
    "            \"model\": self.model_name,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"k\": self.k,\n",
    "            \"vectorstores\": {\n",
    "                \"recipes_and_meals\": {\n",
    "                    \"vectors\": self.vectorstore_recipes.index.ntotal\n",
    "                },\n",
    "                \"nutrition_facts\": {\n",
    "                    \"vectors\": self.vectorstore_nutrition.index.ntotal\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(production_code)\n",
    "\n",
    "print(f\"âœ… Production file created: {output_file}\")\n",
    "print(f\"ğŸ“¦ File size: {os.path.getsize(output_file) / 1024:.2f} KB\")\n",
    "print(\"\\nğŸ¯ Next steps:\")\n",
    "print(\"1. Test the exported file:\")\n",
    "print(\"   from src.recipes_nutrition_rag import RecipesNutritionRAG\")\n",
    "print(\"2. Use in your Streamlit app\")\n",
    "print(\"3. Deploy to production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3bae528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Python path configured\n",
      "ğŸ“‚ Project root: c:\\Users\\tranq\\Desktop\\neue_fische\\nutrition-ai-assistant\n",
      "ğŸ“‚ Contents: ['data', 'notebooks', 'src', 'vector_databases']\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# SETUP: Fix Python Path for Import\n",
    "# ========================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"âœ… Python path configured\")\n",
    "print(f\"ğŸ“‚ Project root: {project_root}\")\n",
    "print(f\"ğŸ“‚ Contents: {[f.name for f in project_root.iterdir() if f.name in ['src', 'data', 'notebooks', 'vector_databases']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21db7cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Import successful!\n",
      "ğŸ“¦ Module: src.recipes_nutrition_rag\n",
      "ğŸ“ Docstring preview:\n",
      "\n",
      "    Production-ready RAG system for personalized recipe recommendations.\n",
      "\n",
      "    Features:\n",
      "    - Dual vectorstore system (recipes + nutrition facts)\n",
      "    - Smart query routing (recipes/nutrition/both)\n",
      "  ...\n",
      "\n",
      "ğŸ”§ Available methods:\n",
      "   - SYSTEM_PROMPT\n",
      "   - get_retrieved_docs\n",
      "   - get_stats\n",
      "   - initialize\n",
      "   - query\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TEST: Import Production Module\n",
    "# ========================================\n",
    "\n",
    "# Import the exported class\n",
    "from src.recipes_nutrition_rag import RecipesNutritionRAG\n",
    "\n",
    "print(\"\\nâœ… Import successful!\")\n",
    "print(f\"ğŸ“¦ Module: {RecipesNutritionRAG.__module__}\")\n",
    "print(f\"ğŸ“ Docstring preview:\\n{RecipesNutritionRAG.__doc__[:200]}...\")\n",
    "\n",
    "# Show available methods\n",
    "print(\"\\nğŸ”§ Available methods:\")\n",
    "methods = [m for m in dir(RecipesNutritionRAG) if not m.startswith('_')]\n",
    "for method in methods:\n",
    "    print(f\"   - {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e32615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RecipesNutritionRAG created\n",
      "   Model: llama3.2 | Temperature: 0.5 | k: 10\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸš€ Initializing RecipesNutritionRAG...\n",
      "ğŸ“‚ Loading existing vectorstores...\n",
      "âœ… Initialization complete!\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Production System Statistics:\n",
      "{\n",
      "  \"status\": \"initialized\",\n",
      "  \"model\": \"llama3.2\",\n",
      "  \"temperature\": 0.5,\n",
      "  \"k\": 10,\n",
      "  \"vectorstores\": {\n",
      "    \"recipes_and_meals\": {\n",
      "      \"vectors\": 5090\n",
      "    },\n",
      "    \"nutrition_facts\": {\n",
      "      \"vectors\": 8789\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "âœ… Production RAG system ready for queries!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TEST 2: Initialize Production RAG System\n",
    "# ========================================\n",
    "\n",
    "import json\n",
    "\n",
    "# Create instance using the production module\n",
    "production_rag = RecipesNutritionRAG(\n",
    "    data_folder=\"../data/\",\n",
    "    vectorstore_path=\"../vector_databases/\",\n",
    "    model_name=\"llama3.2\",\n",
    "    temperature=0.5,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# Initialize (loads existing vectorstores)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "production_rag.initialize(force_rebuild=False)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verify system stats\n",
    "stats = production_rag.get_stats()\n",
    "print(\"\\nğŸ“Š Production System Statistics:\")\n",
    "print(json.dumps(stats, indent=2))\n",
    "\n",
    "print(\"\\nâœ… Production RAG system ready for queries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceec8e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Query type detected: RECIPES\n",
      "   â†’ Searched RECIPES_AND_MEALS collection\n",
      "### Recipe Name: Garden Soup (American Lunch)\n",
      "\n",
      "**2. Why This Recipe:**\n",
      "- Meets calorie/protein requirements\n",
      "- Dietary compliance (vegetarian)\n",
      "- Medical alignment (if applicable): suitable for most adults with normal health conditions\n",
      "\n",
      "**3. Adaptations Made:** \n",
      "Original â†’ Modified â†’ Reason:\n",
      "No adaptations needed\n",
      "\n",
      "**4. Nutritional Information (per serving):**\n",
      "- Calories: 235 kcal\n",
      "- Protein: 64.9g | Carbs: 18.0g | Fat: 48.1g\n",
      "- Fiber: 24.4g | Sugar: 46.2g\n",
      "- Sodium: 2499mg | Cholesterol: 24mg\n",
      "\n",
      "**5. Ingredients (CRITICAL - NEVER SKIP):**\n",
      "- 265g mixed vegetables (broccoli, carrots, bell peppers) (- approximately 250g)\n",
      "- 15g olive oil (- 15ml)\n",
      "- 1 tsp dried thyme (- 5ml)\n",
      "- 1 tsp dried rosemary (- 5ml)\n",
      "- Salt and pepper to taste (- negligible)\n",
      "\n",
      "**6. Cooking Instructions (CRITICAL - NEVER SKIP):**\n",
      "1. Preheat the oven to 180Â°C.\n",
      "2. In a large bowl, combine mixed vegetables, olive oil, thyme, and rosemary. Toss until evenly coated.\n",
      "3. Spread the mixture on a baking sheet and roast for 45 minutes or until tender.\n",
      "4. Season with salt and pepper to taste.\n",
      "\n",
      "**7. Time Information:**\n",
      "- Preparation Time: 10 minutes\n",
      "- Cooking Time: 45 minutes\n",
      "- Total Time: 55 minutes\n"
     ]
    }
   ],
   "source": [
    "query = production_rag.query(\"find a vegetarian recipe with under 600 kcals\")\n",
    "print(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
