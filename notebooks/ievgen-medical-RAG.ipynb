{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f75b3f81",
   "metadata": {},
   "source": [
    "# RAG on Medical PDFs - Nutrition Restrictions Extraction\n",
    "\n",
    "This notebook extracts nutrition restrictions and dietary guidelines from medical PDF documents.\n",
    "The output is a structured JSON that can be used in other RAG systems for personalized nutrition advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36824fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain imports for RAG\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Hybrid search imports\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# Ollama LLM\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Additional utilities\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Path to PDF documents\n",
    "PDF_FOLDER = \"../data/pdfs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lqjboazve9a",
   "metadata": {},
   "source": [
    "## 1. Load PDF Documents\n",
    "\n",
    "We load all PDF files from the `data/pdfs/` folder. These contain medical nutrition guidelines that will be used to extract dietary restrictions and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9lf4tix2m0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 PDF files:\n",
      "  - 10-61474-ncs-2025-00004.pdf\n",
      "  - Eating-Well-with-Parkinsons-Disease.pdf\n",
      "  - northwestern-medicine-summary-of-nutritional-guide-for-parkinsons-disease.pdf\n",
      "  - Nutrition-Parkinsons_A4Manual_Aug2021.pdf\n",
      "  - PARKINSON1614-Guideline-Nutrition-A4-ENG.pdf\n",
      "Loaded 13 pages from 10-61474-ncs-2025-00004.pdf\n",
      "Loaded 36 pages from Eating-Well-with-Parkinsons-Disease.pdf\n",
      "Loaded 2 pages from northwestern-medicine-summary-of-nutritional-guide-for-parkinsons-disease.pdf\n",
      "Loaded 44 pages from Nutrition-Parkinsons_A4Manual_Aug2021.pdf\n",
      "Loaded 39 pages from PARKINSON1614-Guideline-Nutrition-A4-ENG.pdf\n",
      "\n",
      "Total pages loaded: 134\n"
     ]
    }
   ],
   "source": [
    "# List all PDF files in the folder\n",
    "pdf_files = list(Path(PDF_FOLDER).glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for f in pdf_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Load all PDFs\n",
    "all_documents = []\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        loader = PyPDFLoader(str(pdf_path))\n",
    "        docs = loader.load()\n",
    "        # Add source filename to metadata\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source_file\"] = pdf_path.name\n",
    "        all_documents.extend(docs)\n",
    "        print(f\"Loaded {len(docs)} pages from {pdf_path.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal pages loaded: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ra9hn8xrkri",
   "metadata": {},
   "source": [
    "## 2. Chunk Documents for RAG\n",
    "\n",
    "Unlike tabular nutrition data, PDF documents contain long-form text that needs to be split into smaller chunks for effective retrieval. We use:\n",
    "- **Chunk size**: 1000 characters (captures meaningful paragraphs)\n",
    "- **Overlap**: 200 characters (maintains context across chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cmdjzou8ps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 356 chunks from 134 pages\n",
      "Average chunk length: 797 characters\n",
      "\n",
      "--- Example chunk ---\n",
      "possible causes including pesticides and brain injury. In familial cases of PD, however, a set of genes have been identified \n",
      "as causes of PD, including the Î±- synuclein gene, Parkin, PTEN-induced kinase 1, and Leucine-rich repeat kinase 2 . To \n",
      "date, there is no cure for this disease, except for some palliative treatments such as dopa/dopamine therapy. Dopamine \n",
      "administration from external sources is effective only for a couple of years; after that, dyskinesia and other neurological \n",
      "complicat...\n",
      "\n",
      "Metadata: {'source': '..\\\\data\\\\pdfs\\\\10-61474-ncs-2025-00004.pdf', 'page': 0, 'source_file': '10-61474-ncs-2025-00004.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Create text splitter for chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = text_splitter.split_documents(all_documents)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks from {len(all_documents)} pages\")\n",
    "print(f\"Average chunk length: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} characters\")\n",
    "\n",
    "# Preview a chunk\n",
    "print(\"\\n--- Example chunk ---\")\n",
    "print(chunks[5].page_content[:500] + \"...\")\n",
    "print(f\"\\nMetadata: {chunks[5].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ihagm1k8eua",
   "metadata": {},
   "source": [
    "## 3. Create Embeddings and Vector Store\n",
    "\n",
    "We use `BAAI/bge-small-en-v1.5` for embeddings - optimized for retrieval tasks with good performance on medical/scientific text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pm85dcenhji",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\ai_ds_bootcamp\\nutrition-ai-assistent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded: BAAI/bge-small-en-v1.5\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Initialize HuggingFace embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"Embedding model loaded: BAAI/bge-small-en-v1.5\")\n",
    "print(f\"Embedding dimension: {len(embeddings.embed_query('test'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qync4zby6ws",
   "metadata": {},
   "source": [
    "## 4. Create Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "r23ejx90ou8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 356 vectors\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS vector store from chunks\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    distance_strategy=DistanceStrategy.COSINE\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mahjhojgg3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store saved to ../data/processed/medical_pdfs_vectorstore\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save vector store for later use\n",
    "VECTORSTORE_PATH = \"../data/processed/medical_pdfs_vectorstore\"\n",
    "\n",
    "# Uncomment to save\n",
    "vectorstore.save_local(VECTORSTORE_PATH)\n",
    "print(f\"Vector store saved to {VECTORSTORE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y19krpfun7d",
   "metadata": {},
   "source": [
    "## 5. Create Hybrid Retriever\n",
    "\n",
    "Combining BM25 (keyword) and vector search for better retrieval of medical terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "kis8xnfvqw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever created (BM25 + Vector with MMR)\n",
      "\n",
      "Test query: What foods should be avoided with Parkinson's disease?\n",
      "Retrieved 9 documents\n"
     ]
    }
   ],
   "source": [
    "# Create BM25 retriever for keyword matching\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "# Create vector retriever with MMR for diverse results\n",
    "vector_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"fetch_k\": 20,\n",
    "        \"lambda_mult\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "# Combine both retrievers\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.4, 0.6]\n",
    ")\n",
    "\n",
    "print(\"Hybrid retriever created (BM25 + Vector with MMR)\")\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"What foods should be avoided with Parkinson's disease?\"\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "print(f\"\\nTest query: {test_query}\")\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ysdlo3egflb",
   "metadata": {},
   "source": "## 6. Define Simple JSON Output Schema for Nutrition Parameters\n\nThe output is a simple set of nutrition constraints that can be passed directly to the recipes/nutrition RAG for filtering recommendations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nk6kgeeg8oq",
   "metadata": {},
   "outputs": [],
   "source": "# Simple JSON schema for nutrition parameters\n# Each parameter has: target value, min/max limits, unit, and priority\n\nNUTRITION_PARAMS_SCHEMA = {\n    \"condition\": \"string - medical condition\",\n    \"daily_targets\": {\n        \"calories\": {\"min\": 0, \"max\": 0, \"unit\": \"kcal\"},\n        \"protein_g\": {\"min\": 0, \"max\": 0, \"unit\": \"g\", \"notes\": \"\"},\n        \"fiber_g\": {\"min\": 0, \"max\": 0, \"unit\": \"g\"},\n        \"sodium_mg\": {\"min\": 0, \"max\": 0, \"unit\": \"mg\"},\n        \"water_ml\": {\"min\": 0, \"max\": 0, \"unit\": \"ml\"}\n    },\n    \"per_meal_limits\": {\n        \"protein_g\": {\"max\": 0, \"notes\": \"timing with medication\"}\n    },\n    \"increase\": [\"list of nutrients/foods to prioritize\"],\n    \"limit\": [\"list of nutrients/foods to reduce\"],\n    \"avoid\": [\"list of foods to exclude\"],\n    \"timing_notes\": [\"medication-related timing advice\"]\n}\n\nprint(\"Simple Nutrition Parameters Schema:\")\nprint(json.dumps(NUTRITION_PARAMS_SCHEMA, indent=2))"
  },
  {
   "cell_type": "markdown",
   "id": "1z54uc297zd",
   "metadata": {},
   "source": [
    "## 7. Connect to Ollama LLM\n",
    "\n",
    "Prerequisites:\n",
    "1. Install Ollama: https://ollama.ai/\n",
    "2. Pull a model: `ollama pull llama3.2`\n",
    "3. Start Ollama: `ollama serve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6g0zhwwiodr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Ollama LLM\n",
    "llm = OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.3,  # Lower temperature for more consistent JSON output\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "test_response = llm.invoke(\"Say 'Connection successful!' if you can read this.\")\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4weubngeh0h",
   "metadata": {},
   "source": [
    "## 8. Create RAG Chain for Nutrition Restrictions Extraction\n",
    "\n",
    "The prompt is designed to extract structured nutrition restrictions from medical documents and return valid JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffywyc0x47t",
   "metadata": {},
   "outputs": [],
   "source": "# System prompt for extracting simple nutrition parameters\nextraction_system_prompt = \"\"\"You are a medical nutrition specialist. Extract nutrition parameters from medical documents.\n\nOUTPUT FORMAT - Return ONLY valid JSON with this exact structure:\n{{\n    \"condition\": \"Parkinson's Disease\",\n    \"daily_targets\": {{\n        \"calories_kcal\": {{\"min\": number, \"max\": number}},\n        \"protein_g\": {{\"min\": number, \"max\": number}},\n        \"fiber_g\": {{\"min\": number, \"max\": number}},\n        \"sodium_mg\": {{\"min\": number, \"max\": number}},\n        \"water_ml\": {{\"min\": number, \"max\": number}},\n        \"calcium_mg\": {{\"min\": number, \"max\": number}},\n        \"vitamin_d_iu\": {{\"min\": number, \"max\": number}}\n    }},\n    \"per_meal_limits\": {{\n        \"protein_g\": {{\"max\": number, \"reason\": \"string\"}}\n    }},\n    \"increase\": [\"nutrient or food to eat more of\"],\n    \"limit\": [\"nutrient or food to reduce\"],\n    \"avoid\": [\"foods to completely avoid\"],\n    \"timing_notes\": [\"when to eat relative to medication\"]\n}}\n\nRULES:\n1. Use numbers only (no units in values), use 0 if not specified\n2. Extract from context only - don't invent values\n3. For Parkinson's: pay attention to protein timing with Levodopa\n4. Include fiber (for constipation) and hydration recommendations\n5. Return ONLY the JSON, no other text\n\nCONTEXT:\n{context}\"\"\"\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", extraction_system_prompt),\n    (\"human\", \"{input}\")\n])\n\n# Create the RAG chain\nquestion_answer_chain = create_stuff_documents_chain(llm, prompt)\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\n\nprint(\"RAG chain created for nutrition parameters extraction!\")"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5iudiuxl9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction functions defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_nutrition_restrictions(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract nutrition restrictions from medical PDFs based on a query.\n",
    "    Returns a structured JSON dictionary.\n",
    "    \"\"\"\n",
    "    response = rag_chain.invoke({\"input\": query})\n",
    "    raw_answer = response[\"answer\"]\n",
    "    \n",
    "    # Try to parse as JSON\n",
    "    try:\n",
    "        # Clean up the response - remove any markdown code blocks\n",
    "        cleaned = raw_answer.strip()\n",
    "        if cleaned.startswith(\"```json\"):\n",
    "            cleaned = cleaned[7:]\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned[3:]\n",
    "        if cleaned.endswith(\"```\"):\n",
    "            cleaned = cleaned[:-3]\n",
    "        cleaned = cleaned.strip()\n",
    "        \n",
    "        result = json.loads(cleaned)\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": result,\n",
    "            \"sources\": [doc.metadata.get(\"source_file\", \"unknown\") for doc in response[\"context\"]]\n",
    "        }\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"raw_response\": raw_answer,\n",
    "            \"error\": str(e),\n",
    "            \"sources\": [doc.metadata.get(\"source_file\", \"unknown\") for doc in response[\"context\"]]\n",
    "        }\n",
    "\n",
    "\n",
    "def save_restrictions_to_json(restrictions: Dict[str, Any], output_path: str):\n",
    "    \"\"\"Save extracted restrictions to a JSON file.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(restrictions, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Restrictions saved to: {output_path}\")\n",
    "\n",
    "\n",
    "print(\"Extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lbpz4pwm0h",
   "metadata": {},
   "source": [
    "## 9. Extract Nutrition Restrictions\n",
    "\n",
    "Now we extract all nutrition restrictions from the medical PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k5efr2uuqoi",
   "metadata": {},
   "outputs": [],
   "source": "# Extract nutrition parameters for Parkinson's disease\nquery = \"\"\"What are the recommended daily nutrition parameters for Parkinson's disease patients?\nExtract: calories, protein (daily and per-meal limits), fiber, sodium, water intake, calcium, vitamin D.\nAlso list foods to increase, limit, and avoid. Include any medication timing notes for Levodopa.\"\"\"\n\nprint(\"Extracting nutrition parameters...\")\nresult = extract_nutrition_restrictions(query)\n\nif result[\"success\"]:\n    print(\"âœ“ Successfully extracted parameters!\\n\")\n    print(json.dumps(result[\"data\"], indent=2))\nelse:\n    print(\"âœ— Could not parse as JSON\")\n    print(f\"Error: {result['error']}\\n\")\n    print(\"Raw response:\")\n    print(result[\"raw_response\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "he81mjwwyxf",
   "metadata": {},
   "outputs": [],
   "source": "# Save nutrition parameters to JSON file\nOUTPUT_PATH = \"../data/processed/nutrition_params_parkinsons.json\"\n\nif result[\"success\"]:\n    save_restrictions_to_json(result[\"data\"], OUTPUT_PATH)\n    print(\"\\nThis JSON can be loaded by the nutrition RAG to filter recipes!\")\nelse:\n    fallback_data = {\n        \"condition\": \"Parkinson's Disease\",\n        \"raw_text\": result[\"raw_response\"],\n        \"note\": \"Manual parsing needed\"\n    }\n    save_restrictions_to_json(fallback_data, OUTPUT_PATH.replace(\".json\", \"_raw.json\"))"
  },
  {
   "cell_type": "markdown",
   "id": "7c79f56c",
   "metadata": {},
   "source": "## 10. Example: View Extracted Parameters"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c432c0",
   "metadata": {},
   "outputs": [],
   "source": "# Display the extracted parameters in a readable format\nif result[\"success\"]:\n    data = result[\"data\"]\n    \n    print(\"=\" * 50)\n    print(f\"CONDITION: {data.get('condition', 'Unknown')}\")\n    print(\"=\" * 50)\n    \n    print(\"\\nðŸ“Š DAILY TARGETS:\")\n    for nutrient, values in data.get(\"daily_targets\", {}).items():\n        if isinstance(values, dict):\n            print(f\"  {nutrient}: {values.get('min', 0)} - {values.get('max', 0)}\")\n    \n    print(\"\\nðŸ½ï¸ PER-MEAL LIMITS:\")\n    for nutrient, values in data.get(\"per_meal_limits\", {}).items():\n        if isinstance(values, dict):\n            print(f\"  {nutrient}: max {values.get('max', 0)} ({values.get('reason', '')})\")\n    \n    print(\"\\nâœ… INCREASE (eat more):\")\n    for item in data.get(\"increase\", []):\n        print(f\"  â€¢ {item}\")\n    \n    print(\"\\nâš ï¸ LIMIT (reduce):\")\n    for item in data.get(\"limit\", []):\n        print(f\"  â€¢ {item}\")\n    \n    print(\"\\nâŒ AVOID:\")\n    for item in data.get(\"avoid\", []):\n        print(f\"  â€¢ {item}\")\n    \n    print(\"\\nâ° TIMING NOTES:\")\n    for note in data.get(\"timing_notes\", []):\n        print(f\"  â€¢ {note}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114ba3a6",
   "metadata": {},
   "outputs": [],
   "source": "# The output JSON structure - ready for use in nutrition RAG\nprint(\"Output JSON file:\", OUTPUT_PATH)\nprint(\"\\nThis file contains nutrition parameters that can be used to:\")\nprint(\"1. Filter recipes by protein content per meal\")\nprint(\"2. Prioritize high-fiber foods\")\nprint(\"3. Exclude foods from the 'avoid' list\")\nprint(\"4. Apply timing rules relative to medication\")"
  },
  {
   "cell_type": "markdown",
   "id": "km6xkk49wb9",
   "metadata": {},
   "source": "## 11. Using Nutrition Parameters in Recipe RAG\n\nThe JSON output can filter recipes based on the extracted constraints."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cqxml2nz7hr",
   "metadata": {},
   "outputs": [],
   "source": "# Example: How to use nutrition params in recipe RAG\n\ndef load_nutrition_params(json_path: str) -> Dict[str, Any]:\n    \"\"\"Load nutrition parameters from JSON.\"\"\"\n    with open(json_path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n\ndef check_recipe_fits_params(recipe_nutrition: Dict, params: Dict) -> bool:\n    \"\"\"Check if a recipe fits within the nutrition parameters.\"\"\"\n    daily = params.get(\"daily_targets\", {})\n    \n    # Check protein limit per meal\n    meal_limits = params.get(\"per_meal_limits\", {})\n    if \"protein_g\" in meal_limits:\n        max_protein = meal_limits[\"protein_g\"].get(\"max\", 999)\n        if recipe_nutrition.get(\"protein_g\", 0) > max_protein:\n            return False\n    \n    # Check sodium\n    if \"sodium_mg\" in daily:\n        max_sodium = daily[\"sodium_mg\"].get(\"max\", 999999)\n        if recipe_nutrition.get(\"sodium_mg\", 0) > max_sodium / 3:  # per meal\n            return False\n    \n    return True\n\n# Example usage:\n# params = load_nutrition_params(\"../data/processed/nutrition_params_parkinsons.json\")\n# print(\"Foods to increase:\", params.get(\"increase\", []))\n# print(\"Foods to avoid:\", params.get(\"avoid\", []))\n# print(\"Per-meal protein limit:\", params.get(\"per_meal_limits\", {}).get(\"protein_g\", {}))\n\nprint(\"Helper functions ready for recipe filtering!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}